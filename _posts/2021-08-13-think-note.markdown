---
layout:     post
title:      "灯泡时刻（不定期更新）"
subtitle:   "突然对某个知识点有疑问的笔记"
date:       2021-08-13
author:     "CSoap"
header-img: "img/home-bg-o.jpg"
tags:
    - 知识点
---

- 网络
    - 网络模型
        - https://www.jianshu.com/p/bb363a41afcf
        ![network-compare-model](/img/in-post/post-js-version/net_1.jpg "network-compare-model")

        - 开放式系统互联模型（Open System Interconnection Model，缩写为 OSI model，简称为 OSI 模型）
            - https://blog.csdn.net/weixin_45610260/article/details/105212469
            - 物理层 比特流的发送
            - 数据链路层 引入mac地址,提供了将数据从一台可寻址的电脑发送到其他电脑
            - 网络层,即路由层,a要发给F,要经过bcde,路由获得**最佳路径**;网络层用于将数据从一台主机传输到位于不同网络中的另一台主机,对比链路层只认mac地址,不认识ip地址
                - IP协议：版本，首部长度，区分服务，总长度，生存时间（丢弃无法交付数据报），协议，首部校验和，标识（相同数据报不同分片标识相同），片偏移
                - 路由器：路由选择，分组转发
                - ARP协议：由IP地址得到物理地址(MAC地址)
                - ICMP协议：差错报告报文，询问报文. 例:ping
                - 路由选择协议,路由器：路由选择，分组转发
                - 内部网关协议,外部网关协议
                - VPN：虚拟专用网
                - NAT：网络地址转换
            - 传输层,实现各个进程之间的通信,为了区别同意同一系统上的不同进程通讯引入端口; 提供端到端的消息传递服务，发送成功后返回确认、数据出错后重发的功能
                - UDP：无连接，不可靠，面向报文
                    - 首部：源端口，目的端口，长度，校验和
                    - 伪首部：源IP，目的IP，0，17，UDP长度，为计算校验和临时添加
                - TCP：有连接，可靠，面向字节流，有流量控制，有拥塞控制
                    - 首部：源端口，目的端口，序号，确认号（期望收到的下一个报文段编号），数据偏移（首部长度），URG，ACK，PSH，RST，SYN，FIN，窗口（接收方期望窗口大小），检验和，紧急指针
                - 可靠传输：超时重传
                - 流量控制：让接收方来得及接收
                - 拥塞控制：降低网络拥塞
                - 慢开始：初始cwnd=1，收到确认后加倍
                - 拥塞避免：当cwnd>=ssthresh时，cwnd每次加1，出现超时，ssthresh=cwnd/2，重新执行慢开始
                - 快重传：收到连续三个重复确认，立即重传下一个报文段
                - 快恢复：ssthresh=cwnd/2，cwnd=ssthresh，执行拥塞避免
            - 会话层, 会话层负责建立连接，维护会话、认证，并确保安全
            - 表示层, 转换层,解决不同系统之间的通信语法问题,此层主要对数据进行翻译,加密,解密,压缩
            - 应用层, 应用层是 app 访问网络、向用户显示接收到信息的窗口.
                - 例:HTTP协议 FTP协议 SMTP协议
        - 五层模型
        - TCP/IP 四层模型
            - 通信的过程其实是对应数据的入栈和出栈
                ![network--model](/img/in-post/post-js-version/net_2.png)
    - TCP/IP协议的核心是TCP、UDP和IP协议
        - 由网络层的**IP协议**和传输层的**TCP协议**组成。通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台联网设备规定一个地址
    - post、get
        - 区别
            - 都包含请求头请求行，post多了请求body
            - get多用来查询，请求参数放在url中，不会对服务器上的内容产生作用。post用来提交，如把账号密码放入body中
            - GET是直接添加到URL后面的，直接就可以在URL中看到内容，而POST是放在报文内部的，用户无法直接看到
            - GET提交的数据长度是有限制的，因为URL长度有限制，具体的长度限制视浏览器而定。而POST没有
    - 响应状态码
        - 状态码分类
            - 1XX- 信息型，服务器收到请求，需要请求者继续操作
            - 2XX- 成功型，请求成功收到，理解并处理
            - 3XX - 重定向，需要进一步的操作以完成请求
            - 4XX - 客户端错误，请求包含语法错误或无法完成请求
            - 5XX - 服务器错误，服务器在处理请求的过程中发生了错误
        - 常见状态码
            - 200 OK - 客户端请求成功
            - 301 - 资源（网页等）被永久转移到其它URL
            - 302 - 临时跳转
            - 400 Bad Request - 客户端请求有语法错误，不能被服务器所理解
            - 401 Unauthorized - 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用
            - 403 禁止访问 服务器拒绝请求
            - 404 请求资源不存在，可能是输入了错误的URL
            - 405 请求方法不允许 408 请求超时
            - 500 - 服务器内部发生了不可预期的错误
            - 503 Server Unavailable - 服务器当前不能处理客户端的请求，一段时间后可能恢复正常。
            - 505 服务器不支持改http版本
    - 计算客户端与服务器之间的时间延迟
        - 数据包发送的整个流程
            - 客户端A先记录自己的本地时间TA1，然后给服务器发B发送一个报文
            - 服务器B收到报文之后，记录自己的本地时间TB，然后把TB放入报文里发送给客户端A。
            - 客户端A收到信息之后，记录下收到报文的时间TA2.
            - 由于报文往返的时间是相等的，所以客户端发送给服务器的时间延迟P = （TA2 - TA1）/ 2。一般，P只计算一次是不够精确的。我们可以让客户端A定时的给服务器B发送测量信息，然后计算P的平均值。TA2 - TA1 也就是ping值
        - 客户端和服务器的本地时间差，可以怎么获取
            - 先假设A和B的本地时钟是一样的（当然这个假设明显不成立），则TB = TA1 + P ，把上面的P套入公式，整理后可以得TB = (TA1 + TB2) / 2
            - 可是实际上A和B之间是有时间差X的，于是 TB + X = （TA1 + TB2）/ 2,整理后可得X = （TA1 + TA2）/ 2  - TB
    - ping是什么协议
        - ICMP协议（internet控制消息协议），用于在在ip主机、路由器之间传递**控制消息**，控制消息指网络通不通、主机是否可达、路由是否可用等消息
        - ping的原理是向指定的ip地址发送一定长度的数据包，若目标存在会返回一样大小的数据包。有些防火墙会屏蔽ICMP，所以ping只能参考
    - http和https
        - https://blog.csdn.net/xiaoming100001/article/details/81109617
        - http
            - 是什么?
                - 超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议,所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法
            - 流程
                - 打开HTTP连接,因为HTTP是无状态协议,每次请求需要建立一个新的连接
                - 初始化方法请求
                - 设置HTTP请求头(数据类型+数据长度)
                - 发送请求
                - 读取请求,调用方法.
                - 设置HTTP响应头(数据类型+数据长度)
                - 发送响应
                - 关闭连接
            - 特点?
                - 无状态：协议对客户端没有状态存储,比如访问一个网站需要反复进行登录操作
                    - 针对无状态的一些解决策略,比如执行一次登陆操作，在30分钟内所有的请求都不需要再次登陆
                        - 通过Cookie/Session技术
                        - HTTP/1.1默认使用长连接，只要任意一端没有明确提出断开连接，则保持TCP连接状态,在请求头的Connection: keep-alive即为表明使用了持久连接
                - 无连接：HTTP/1.1之前，由于无状态特点，每次请求需要通过TCP三次握手四次挥手
                - 基于请求和响应：基本的特性，由客户端发起请求，服务端响应
                - 简单快速、灵活
                - 通信使用明文(纯文本)、请求和响应不会对通信方进行确认、无法保护数据的完整性
            - 报文组成
                - 请求报文构成
                    - 请求行:请求方法(post,get),URL,协议/版本
                    - 请求头(Request Header)
                    - 请求正文
                - 响应报文构成
                    - 状态行
                    - 响应头
                    - 响应正文

                ![报文构成](/img/in-post/post-js-version/net_3.png)

            - http2.0在1.1基础上有何优化
                - 头部优化
                    - 1.1版本会把所有的头部信息发送,2.0会在两端建立**索引表**,发送的时候直接传递key值(增大实时性,并发性)
                - 分流
                    - 信息分割为更小的消息和帧
                - 多路复用
                    - 单个tcp链接,解决多次http请求(多个请求,变成3个流,放入同一个tcp请求里)

        - https
            - https://www.bilibili.com/video/BV1Do4y117ez
            - 是什么?
                - HTTPS是身披SSL外壳的HTTP。HTTPS是一种通过计算机网络进行安全通信的传输协议，经由HTTP进行通信，利用SSL/TLS建立全信道，加密数据包
                > TLS是传输层加密协议，前身是SSL协议
            - 特点
                - 内容加密：采用混合加密技术，中间者无法直接查看明文内容
                > 混合加密:结合**非对称加密和对称加密**技术。**客户端使用对称加密生成密钥对传输数据进行加密，然后使用非对称加密的公钥再对秘钥进行加密**，所以网络上传输的数据是**被秘钥加密的密文**和用**公钥加密后的秘密秘钥**，因此即使被黑客截取，由于没有私钥，无法获取到加密明文的秘钥，便无法获取到明文数据。

                > 数字摘要:通过**单向hash函数对原文进行哈希**，将需加密的明文“摘要”成一串固定长度(如128bit)的密文，不同的明文摘要成的密文其结果总是不相同，同样的明文其摘要必定一致，并且即使知道了摘要也不能反推出明文。

                > 公钥从何而来? 公钥就被包含在数字证书中，数字证书通常来说是由受信任的数字证书颁发机构CA，证书中包含了一个密钥对（公钥和私钥）和所有者识别信息。数字证书被放到服务端

                - 验证身份：通过证书认证客户端访问的是自己的服务器
                - 保护数据完整性：防止传输的内容被中间人冒充或者篡改
            - https协议的通信加密过程
                ![https验证过程](/img/in-post/post-js-version/https_1.png)
            - 优点
                - 认证用户和服务器,确保数据发送到正确的客户端和服务器
                - 防止数据在传输过程中不被窃取、改变，确保数据的完整性。
                - 谷歌曾在2014年8月份调整搜索引擎算法，比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高
            - 缺点
                - 握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电
                - HTTPS连接缓存不如HTTP高效,流量成本高。
                - SSL证书需要钱
                - 在某些国家可以控制CA根证书的情况下，中间人攻击一样可行
    - 重传机制
        - 为什么?发出去的请求包在规定时间内没有收到ACK，不管是请求包丢失，还是ACK包丢失，还是网络延迟,都需要重传机制,
            - 有两种类型重传机制
                - 超时重传
                    - 在请求包发出去的时候，开启一个计时器，当计时器达到时间(RTO 重传过期时间)之后，没有收到ACK，则就进行重发请求的操作，一直重发直到达到重发上限次数或者收到ACK
                    > RTO不是静态配置的，在这个问题里系统会根据前面三次握手和第一个报文的ack的RTT计算出来一个RTO
                - 快速重传
                    - 当接收方收到的数据包是不正常的序列号，那么接收方会重复把应该收到的那一条ACK重复发送，这个时候，如果发送方收到连续3条的同一个序列号的ACK，那么就会启动快速重传机制，把这个ACK对应的发送包重新发送一次
    - TCP和UDP区别
        - https://www.bilibili.com/video/BV1Yo4y1m7Ti
        - TCP面向连接，UDP面向非连接即发送数据前不需要建立链接
        - TCP提供可靠的服务（数据传输），UDP无法保证
            - TCP如何实现可靠性传输(不会出现丢失或乱序)
                - 确认机制、重传机制、滑动窗口。
            - UDP如何实现可靠性传输
                - https://blog.csdn.net/gettogetto/article/details/76736365
                - 传输层无法保证数据的可靠传输，只能通过**应用层**来实现
                    > UDP要想可靠，就要接收方收到UDP之后**回复个确认包**，发送方有个机制，收不到确认包就要重新发送，每个包有递增的序号，接收方发现中间丢了包就要发**重传请求**，当网络太差时候频繁丢包，防止越丢包越重传的恶性循环，要有个**发送窗口的限制**，发送窗口的大小根据网络传输情况调整，调整算法要有一定自适应性。
                    - 详细说明
                        - 送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。
                    - 步骤
                        - 添加seq/ack机制，确保数据发送到对端
                        - 添加发送和接收缓冲区，主要是用户超时重传。
                        - 添加超时重传机制。
                - 市面上已有方案:QUIC(quick udp Internet Connetction),google实现,使用http3.0
                    - 自定义连接机制,只需要握手一次
                - RUDP 塞控制的改进、重发机制及淡化服务器算法
                - KCP知道吗
                    - KCP的开源库，就是可靠的UDP
                    - KCP尽可能保留UDP快的特点下，保证可靠
        - TCP面向字节流，UDP面向报文
            - tcp为什么用数据流?为了保证可靠传输,尽量减少开销.因为可以减少发送包的数量,从而减少额外开销
            - 为什么 TCP 叫数据流模式？ UDP 叫数据报模式？
                - 所谓的“流模式”，是指TCP发送端发送几次数据和接收端接收几次数据是没有必然联系的，比如你通过 TCP连接给另一端发送数据，你只调用了一次 write，发送了100个字节，但是对方可以分10次收完，每次10个字节；你也可以调用10次write，每次10个字节，但是对方可以一次就收完。
                - 原因：这是因为TCP是面向连接的，一个 socket 中收到的数据都是由同一台主机发出，且有序地到达，所以每次读取多少数据都可以。
                - 所谓的“数据报模式”，是指UDP发送端调用了几次 write，接收端必须用相同次数的 read 读完。UDP是基于报文的，在接收的时候，每次最多只能读取一个报文，报文和报文是不会合并的，如果缓冲区小于报文长度，则多出的部分会被丢弃。
                - 原因：这是因为UDP是无连接的，只要知道接收端的 IP 和端口，任何主机都可以向接收端发送数据。 这时候，如果一次能读取超过一个报文的数据， 则会乱套。
        - TCP数据传输慢，UDP数据传输快
        - 在一个TCP连接中，仅有两方进行彼此通信，因此广播和多播不能用于TCP;UDP不会建立连接,可以传给任何人数据,甚至可以同时传给多个人数据
        - udp、tcp的发包大小限制
        - UDP的段结构比TCP段结构简单,因此网络开销也小
        - 如果让你做这种双人合作闯关游戏，你选择tcp还是udp，为什么？
            - tcp，tcp更稳定。
                - 你说要用tcp，tcp在你这种强连接中的一般比较慢，为什么？
                - 校验重传/流量控制/拥塞控制/资源消耗大
    - TCP
        - https://www.zhihu.com/question/28943943/answer/2010426071
        - 例子
            - FTP：定义了文件传输协议，使用21端口;HTTP：是从Web服务器传输超文本到本地浏览器的传送协议;端口默认80,Telnet 一种用于远程登陆的端口，使用23端口;SMTP 邮件传输协议,发送邮件 25端口;POP3,POP3用于接收邮件,端口110
        - 三次握手 四次挥手
            > seq:"sequance"序列号；ack:"acknowledge"确认号；SYN:"synchronize"请求同步标志；；ACK:"acknowledge"确认标志"；FIN："Finally"结束标志。
            - 三次握手建立在哪个函数哪个阶段
            - listen函数是干嘛
            - 三次握手过程
                - 第一次握手，客户端发送SYN包（syn=j）到服务器，并进入SYN_SEND状态，等待服务器确认
                - 第二次握手，服务器收到SYN包，先确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态
                - 第三次握手，客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK（ack=k+1），次包发送完毕进入ESTABLISHED状态，完成三次握手
                    > 确认包的序号,IP的包头里面有TTL(最大生存时间),包如果很晚到达超过TTL就失效了
                ![TCP三次握手](/img/in-post/post-js-version/tcp_wave_3_times.png)
                - https://www.bilibili.com/video/BV1eA411V7RQ

            - 为什么TCP连接需要三次握手，两次不可以吗，为什么？
                - 因为 TCP 是全双工协议，也就是说双方都要关闭，每一方都向对方发送 FIN 和回应 ACK
                - 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。极端的情况可能由于Client端多次重新发送请求数据而导致Server端最后建立了N多个响应在等待，因而造成极大的资源浪费.采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。
            - 如何提升TCP三次握手的性能
                - https://www.bilibili.com/video/BV1D64y1C7sk
                - 客户端
                    - tcp_syn_retries 默认6次, 1+2+4+8+32+64 = 127秒,第一次握手重发
                - 服务端
                    - tcp_synack_retries,默认5次 1+2+4+8+16+32=63秒,二次握手重发(syn+ack)参数,如果失败次数多了会导致长时间记录连接状态.
                    - tcp_max_syn_backlog 半连接状态队列大小
                - Tcp_fastopen,google实现的方案
                    - TFO计数绕过三次握手
                        - 首次连接走正常的三次握手流程
                        - 缓存cookie(第二次握手,服务端携带syn+ack+携带密钥的cookie传给客户端,客户端下次进行三次握手的时候携带cookie进行验证,验证通过即可绕过三次握手)
            - 四次挥手过程
                - https://www.bilibili.com/video/BV1XA411g7wv
                ![TCP四次挥手](/img/in-post/post-js-version/tcp_wave_4_times.png)

                - 假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说"**我Client端没有数据要发给你了**"，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，"**告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息**"。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，"**告诉Client端，好了，我这边数据发完了，准备好关闭连接了**"。Client端收到FIN报文后，"**就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。**“，Server端收到ACK后，"**就知道可以断开连接了"。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了**。Ok，TCP连接就这样关闭了！
            - 为什么客户端最后还要等待2MSL才close？
                - MSL（Maximum Segment Lifetime）报文最长生存时期，TCP允许不同的实现可以设置不同的MSL值。
                - 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，**站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次**，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。
                - 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。
            - 关闭连接确是四次挥手呢？
                - 关闭连接时，服务器收到对方的FIN报文时，仅仅表示**对方不再发送数据了但是还能接收数据**，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次
            - 如何提升四次挥手的性能
                - https://www.bilibili.com/video/BV1AQ4y1d7Ls
                - https://www.jianshu.com/p/a1e2171bbb97
                - 一般主动发起挥手是服务端,释放更多资源可以处理更多连接
        - TCP粘包
            > TCP本来就是基于字节流而不是消息包的协议,会把你的数据变成字节流发到对面去，而且保证顺序不会乱，但是要**自己搞定字节流解析**
            - 粘包是个“土话”，容易引起歧义，不建议沿用。stream2datagram就是stream2datagram，TCP_NODELAY就是TCP_NODELAY，不要说什么“粘包”
            - 什么叫包
                - tcp开发应用的语境下，其实有两种“包”，其一是tcp在传输的时候封装的报文，分为包头和负载，其二是应用开发者在应用层封装的报文结构
            - 什么叫粘
                - 由于tcp是面向流的协议，导致**接收**侧有可能一下子收到多个应用层报文，需要应用开发者自己分开
                - 发送端需要等缓冲区满才发送出去，造成粘包.由于Nagle算法（或者TCP_CORK）的存在，在**发送**的时候，就把应用开发者多次send的数据，“粘”在一个tcp报文里面发出去了，于是，先被send的数据可能需要等待一段时间，才能跟后面被send的数据一起组成报文发出去
            - 怎么做
                - 对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满
                - 人家本身就是个面向流的协议,要自己实现stream2datagram,这不叫解决问题，这叫实现功能
                    - 靠设计一个带包头的应用层报文结构就能解决。包头定长，以特定标志开头，里带着负载长度，这样接收侧只要以定长尝试读取包头，再按照包头里的负载长度读取负载就行了，多出来的数据都留在缓冲区里即可
                - 有人问是否禁止Nagle算法?其实99%的情况下禁不禁止都一样，延迟根本不是Nagle算法导致的；就算真有问题，最优解决方案也不是屏蔽Nagle算法
                    - 设置**TCP_NODELAY**就能屏蔽Nagle算法
            - UDP会不会产生粘包
                - UDP则是面向消息传输的，是有保护**消息边界**的，接收方一次只接受一条独立的信息，所以不存在粘包问题
            - TCP无保护消息边界的解决
                - 发送固定长度的消息
                - 把消息的尺寸与消息一块发送
                - 使用特殊标记来区分消息间隔
        - TCP流量控制 拥塞控制
            - 拥塞控制与**网络的拥堵**情况相关联，而流量控制与**接收方的缓存状态**相关联
            - TCP流量控制
                - https://www.cnblogs.com/kubidemanong/p/9987810.html
                - 流量滑动窗口
                    - 作用:怕发送方把接收方的缓存打满
                ![tcp流量控制](/img/in-post/post-js-version/tcp_1.png)
                - tcp的流量控制相关算法
                    - 流量控制主要针对的是端到端传输中控制流量大小并保证传输可靠性（未收到ack就不滑动）。流量控制往往是指点对点通信量的控制，所要做的是抑制发送端发送数据的**速率**
            - 拥塞控制
                - https://mp.weixin.qq.com/s?__biz=Mzg2NzA4MTkxNQ==&mid=2247485204&idx=1&sn=27daef390eec05b3d5db7cebcdcb4b7c&source=41#wechat_redirect
                - https://blog.csdn.net/qq_41431406/article/details/97926927
                - 拥塞窗口
                    - 作用:怕发送方把带宽网络打满
                - 拥塞控制主要是一个全局性过程，涉及到所有主机，路由器，以及与降低网络传输性能有关的所有因素。防止过多的数据注入到网络中。如果有发生丢包则通过拥塞控制减小窗口，确定出合适(**慢启动 拥塞避免 快重传 快恢复**)的拥塞窗口
        - TCP可靠协议
            - TCP使用校验和，确认和重传机制来保证可靠传输
            - https://www.cnblogs.com/xiaokang01/p/10033267.html
            - TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制
    - UDP
        - UDP报文构成
            - UDP报头,报头由四个16位长（2字节）字段
                - 报文的源端口
                - 目的端口
                - 报文长度
                - 校验值
            - UDP数据区
        - 例子:TFTP（简单文件传输协议 69端口） DNS（域名解析协议 53端口）
        - UDP适用场景
            - 需要资源少,网络状况好的内网或丢包不敏感的应用
            - 不需要一对一链接
            - 需要处理速度快,时延低,容许少量丢包,要求即使网络拥塞,也不能减慢发送速度
    - socket 套接字
        - what? 
            - 和通过文件指针访问文件一样，一个socket就好比一个网络句柄/指针，通过操作这个socket，就能更方便的使用TCP/IP协议栈
            - socket本质上是操作系统对应用程序提供的一个接口，用来封装计算机网络通信的能力
            - socket处于应用层与传输层之间,socket 在这里起到就是连接应用层与传输层的作用
        - 过程
        - 解决多连接并发
            - 多线程的socket服务
        - 阻塞模式 非阻塞模式
            - 概念
                - 默认套接字是阻塞的,每个TCP套接字有一个发送缓冲区.当应用进程调用write,内核从应用进程的缓冲区复制数据到套接字的发送缓冲区,如果发送缓冲区不够容纳,应用进程会被挂起.
            - 区别
                - 发送操作:write writev send sendto sendmsg
                    - 对于TCP套接字来说,write时,如果发送缓冲区没有空间,阻塞模式进程会**挂起**,直到有空间.非阻塞直接返回**err+剩余缓冲区字节**
                    - UDP套接字不存在真正的发送缓冲区
                - 接收 read readv recv recvfrom recvmsg
                    - 对于阻塞的TCP套接字调用上述方法,且套接字的接收缓冲区没有数据可读,进程会被挂起,直到到达新数据,UDP同理.对于非阻塞的套接字调用上述方法则报err
        - 思考,如果一个socket创建后并与80端口绑定后，是否意味着该socket占用了80端口呢？如果是这样的，那么当其accept一个请求后，生成的新的socket到底使用的是什么端口呢?如果是新的端口,防火墙一定会阻止其通过的
            - accept函数返回的新socket其实指代的是本次创建的连接
            - 端口是不变的
    - socket和TCP是什么关系
        - 项目中的拥塞控制如何实现
    - 打开一个网址发生了什么
        - 应用层
            - DNS解析
                - 客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层
                    - DNS域名解析系统的工作原理
                        - 域名和IP地址相互映射的一个分布式数据库
                        - 主机名到IP地址的映射有两种方式
                            - 静态映射，每台设备上都配置主机到IP地址的映射，各设备独立维护自己的映射表，而且只供本设备使用
                            - 动态映射.在解析域名时，可以首先采用静态域名解析的方法，如果静态域名解析不成功，再采用动态域名解析的方法。可以将一些常用的域名放入静态域名解析表中，这样可以大大提高域名解析效率
            - HTTP请求与响应
        - 运输层：在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口
        - 网络层，要经过若干个路由器的转发才能达到目标计算机，这个经过路由器转发的过程称为路由。
        - 链路层，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。

        - 这个属于引导问题,重点考察DNS协议 TCP协议 HTTP协议,步骤如下,然后将其中回答得比较好的协议继续深入
        - DNS解析:将域名解析成IP地址
            - 浏览器会按照一定的频率缓存DNS记录,浏览器会先查询本地host文件,本质是url 映射ip地址,如果本地文件有映射关系,先请求试一下这个IP地址,如果可以直接用,不行再提供过域名解析系统
        - TCP连接:TCP三次握手
        - 发送HTTP请求
        - 服务器处理请求并返回HTTP报文
        - 浏览器解析渲染页面
        - 断开连接:TCP四次挥手

    - 问网络游戏客户端断开网络后服务器端是否可以发现, 为什么, 探测是在应用层做还是传输层做

    - 客户端与服务器端已建立连接，服务器广播数据但客户端一直不接收会发生什么？
    - 详细讲讲在服务器计算和在客户端计算的优缺点。从服务端计算的压力，延迟的考虑，安全性上讲了讲
    - 帧同步 状态同步
        - 帧同步
            - https://zhuanlan.zhihu.com/p/66582899
        - 对比
            - 帧同步:绝大多数MOBA FPS赛车等强交互性的游戏如王者荣耀一般搭配UDP
                - 优点
                    - 开发效率高
                    - 游戏打击感强
                    - 流量消耗稳定且低
                    - 观战/录像重放实现简单
                - 缺点
                    - 网络要求高
                    - 反外挂能力弱
                    - 断线重回时间长
                    - 逻辑性能优化压力
            - 状态同步:纯服务器广播模式的状态同步,绝大多数MMORPG一般搭配TCP
                - 优点
                    - 安全性高
                    - 网络要求宽松,抖动丢包适应性强
                    - 断线重回快
                    - 游戏逻辑性能优化有优势
                - 缺点
                    - 开发效率低
                    - 打击感或惊觉干查
                    - 网络流量随游戏复杂度增加
        - 人物聚集在一个九宫格格子里面得时候如何优化性能
            - 可以用分线或者处理给包定优先级处理，比如国战或者帮派战得时候，装备坐骑，次要显示方面可以优先级别最低同步
    - 《荒野行动》（多人在线游戏，即时性要求高），要选用什么协议？为什么？
    - 点对点和端对端工作在哪层? 工作机制
        - 端到端传输指的是在数据传输前，经过各种各样的交换设备，在两端设备问建立一条链路，就像它们是直接相连的一样，链路建立后，发送端就可以发送数据，直至数据发送完毕，接收端确认接收成功. **主要服务于Application Layer,是说两台主机（终端），跨过网络直接连接**
            - 优点
                - 是链路建立后，发送端知道接收设备一定能收到，而且经过中间交换设备时不需要进行存储转发，因此传输延迟小
            - 缺点
                - 直到接收端收到数据为止，发送端的设备一直要参与传输。如果整个传输的延迟很长，那么对发送端的设备造成很大的浪费。
                - 端到端传输的另一个缺点是如果接收设备关机或故障，那么端到端传输不可能实现
        - 点到点系统指的是发送端把数据传给与它直接相连的设备，这台设备在合适的时候又把数据传给与之直接相连的下一台设备，通过一台一台直接相连的设备，把数据传到接收端.**是说两台主机（终端）在局域网中传输**
            - 优点
                - 发送端设备送出数据后，它的任务已经完成，不需要参与整个传输过程，这样不会浪费发送端设备的资源
            - 缺点
                - 发送端发出数据后，不知道接收端能否收到或何时能收到数据
        - 在一个网络系统的不同分层中，可能用到端到端传输，也可能用到点到点传输。如Internet网，IP及以下各层采用点到点传输，IP层以上采用端到端传输
    - IPv6 对比IPv4 有什么优点
        - 更大的地址空间
        - 更小的路由表
        - 更高的安全性,可以对网络层的数据进行加密并对ip报文进行校验

- 数据结构
    - 线性
        - 数组 连续空间，相同类型
        - 链表 不连续,通过指针串联
            - 手写 插入、删除
        - 单链表 只有后续指针
        - 循环链表 尾节点指针指向头节点
        - 双向链表 既有前指针也有后指针
        - 跳表 带索引的链表
        - 栈 只允许在一端插入删除数据，先进后出
        - 队列 只允许在一段插入,另一端删除,先进先出
    - 非线性
        - 哈希表 把关键字的哈希值作为数组下标
            - 冲突 开放寻址 链表
        - 位图 特殊哈希表,只存布尔值
        - 布隆过滤器 对哈希进行驱魔
        - 二叉树 链式存储,顺序存储
        - 二叉查找树
            - 堆
                - 最大堆
                - 最小堆
            - 红黑树
        - 平衡二叉树 左右子树高度相差不大于1

        - b树
        - B+树
        - 图
- 算法
    - 排序
        - 关键字 排序运算的依据
        - 什么是稳定排序?
            - 待排序的文件中，若存在多个关键字相同的记录，经过排序后这些具有相同关键字记录之间的相对次序保持不变，则排序稳定，反之，相对次序变化，则不稳定。
        - 排序：冒泡、插入、选择、快速、归并、桶、计数、基数、堆
        - 稳定的排序
            - 冒泡、插入、归并、桶、基数、二叉树
        - 不稳定的排序
            - 选择、希尔、堆、快速
            - 思考为何不稳定
        - 快速排序 时间复杂度 O（nlogn） 最坏O（n^2）  空间复杂度 O（logn）
            - 基本思路：通过递归调用快速排序对左右子区间R[low.. pivotpos - 1] 和 R[pivotpos .. hight]快速排序
        - 冒泡排序 时间 O（n^2） 空间 O（1）
        - 插入排序 时间复杂度是 O(n^2) 空间复杂度 O（1）
            -  基本思路：每一步将一个待排序的数据插入到前面已经排好序的有序序列中，直到插完所有元素为止
            - 希尔（shell）排序
                - 希尔排序是把序列按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量的逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个序列恰好被分为一组，算法便终止
                - 假如，定义增量为：gap = len/2，缩小增量以gap = gap/2
        - 桶排序

            ![桶排序](/img/in-post/post-js-version/bucket_1.png)

    - 理论
        - 递归：分解、递推、终止
        - 贪心：在限制值允许的情况下选择期望值最大的
        - 分治：分解、解决、合并
        - 回溯：有规律的枚举所有可能的解，寻找最优,(如果递归不允许使用则使用栈)
        - 动态规划：多阶段决策最优解模型。最优子结构、无后效性、重复子问题
    - 应用
        - 查找
            - 二分查找 时间复杂度 log2n
                - 分别定义三个指针，low、hight、mid，mid=（hight+low）/2，让关键字与mid对比，相等则返回，若关键字小于mid，则hight=mid-1，否则low = mid+1
        - 二叉树遍历
            - 前序、中序、后序
            - 宽度优先,深度优先
        - 图搜索：BFS、DFS
        - 拓扑排序：Kahn、DFS
        - 最短路径：Dijkstra、Bellford、Floyd
        - 最小生成树：Prim、Kruskal
        - 单模匹配：BF、RK、BM、KMP
        - 多模匹配：Trie树、AC自动机
    - 特殊算法
        - 位运算：与、或、异或、左移、右移
    - 游戏相关算法
        - 八叉树查找
        - 碰撞检测
        - A*
    - 两个栈实现一个队列
        - 让其中一个栈作为队列的入口，负责插入新元素；另一个栈作为队列的出口，负责移除老的元素
        - 具体操作:入队时，将元素压入s1。出队时，判断s2是否为空，如不为空，则直接弹出顶元素；如为空，则将s1的元素逐个“倒入”s2，把最后一个元素弹出并出队。这个思路，避免了反复“倒”栈，仅在需要时才“倒”一次。
        - https://blog.csdn.net/ailunlee/article/details/85100514
        - https://www.cnblogs.com/wanghui9072229/archive/2011/11/22/2259391.html
    - 优先队列
    - 双向链表
    - DFS、BFS
    - 快排的时间复杂度和具体实现
    - 一篇英文文章，求每个单词的出现频率？算法的时间复杂度是多少？优化这个算法，能否加快这个过程？
    - TopK问题
        - 第K大的数
            - 暴力法。先将数组排序（nlogn），如果是从大到小，返回第K个，如果从小到大，返回第n-k个（n表示元素个数）
            - 优先队列priorityQueue，内部实现是维护一个大小为k的最小堆。
            - 快速选择算法（快排）
            - 给定一个二叉树, 找出这个二叉树中的一个子树, 使得子树节点最多且子树是一个二叉搜索树, 返回节点总数和子树根节点,
        - 海量数据找出出现次数最高的那个字符串
        - 给你100亿个数，要求求出前1000大的数? 优先队列？小根堆
        - 学习资料 
            - <程序员面试宝典> 最后一章
            - https://blog.csdn.net/zyq522376829/article/details/47686867
    - 动态规划：打家劫舍
    - 快排是稳定的嘛（不是），怎么变稳定（标个位置记录，然后重载运算符时处理）
    - 在一个二维平面中，有一些补给点存在，所有补给点的位置不会改变，玩家可操作角色在平面内随意移动，求在任何时刻距角色最近的补给点。
    - 100*100的二维数组的行优先遍历和列优先遍历除读取顺序外还有哪些区别？
        - 没有好坏，但直接涉及到对内存中数据的最佳存储访问方式
        - 程序访问的内存地址之间连续性越好，程序的访问效率就越高
        - 尽量在行优先机制的编译器，比如**C/C++**等上，采用行优先的数据存储方式
        - 列优先机制的编译器，比如**Matlab**等等上，采用列优先的数据存储方式
    - 一个游戏中，玩家名称为一个全为字母的字符串（不区分大小写），最长不超过10个字符，给出一个目标字符串，要求输出所有含有该目标串的字符
        - 传统字典树是只能处理前缀匹配问题,好像可以用AC自动机

- 设计模式
    - 创建型：工厂，构造，原型，单例，对象池，惰性计算
    - 结构型：装饰器，代理，适配器，外观，享元，MVC
    - 行为型：迭代器，观察者，策略
    - 单例模式有几种写法，安全的要怎么写,可参照剑指Offer
        - 加同步锁前后两次判断实例是否已存在
        - 利用静态构造函数

- 计算机基础
    - n++ 被翻译成三条不同的机器指令
        > n++ 不是原子操作,原子操作指的是不能继续拆分或者被其他操作打断得指令
        - 将内存中的数据加载到CPU得寄存器eax中
        - eax数据+1
        - 计算结果写回内存
    - 0.1+0.2 ~= 0.3
        ![二进制位值](/img/in-post/post-js-version/float_1.png)
        - 0.1 没办法用二进制表示,丢失精度
    - 代码调用栈原理
    - 同步和互斥
        - 同步表现为直接制约,如管道通信,一个进程写,一个进程读,它们是相互制约的
        - 互斥表现为间接制约,比如多个进程同时请求打印机(没使用SPOOLing技术)、多个进程同时请求一张网卡发送数据包等
    - CPU 不执行程序的时候在干什么
        - 计算机的处理器被认为是空闲的.大多数操作系统都有个空闲任务,它是一个特殊的任务。仅当CPU无事可做的时候由操作系统调度器载入它
        - HLT停机指令节省了大量的电能与执量,而空闲任务几乎总是由一个重复执行HLT停机指令的循环组成。
    - cache的作用；怎么在代码级利用局部性；高速缓存是最快的存储器吗
        - what?Cache即CPU的高速缓冲存储器
            - 由于CPU的计算速度远远大于从CPU向内存取数据的速度，如果每次都让CPU去内存取数据，会导致CPU计算能力的浪费，所以人们设计了缓存，CPU通过读写缓存来获取操作数，结果也通过缓存写入内存
        - cache和寄存器区别
            - 缓存不是最快的，寄存器更快。
            - 寄存器是暂时存储的CPU组成部分，cache用来做高度CPU和低速的主存之间加速带。
        - cpu中的缓存和操作系统中的缓存（cache）分别是什么
            - OS操作系统=》快表
                - 目的：提高系统的存取速度
                - 是什么：存放当前访问最频繁的少数活动页面的页号（淘汰算法）
                - 过程：存取数据时，根据数据所在的逻辑页号在快表中找到对应内存块，再联系页内地址，形成物理地址
            - CPU =》 高速缓冲存储器
                - 是什么：是CPU和内存之间的临时存储器
                - 过程：当CPU调用大量数据时候，可以避开内存直接从cache调用，从而加快读取速度
    - 调试的时候打断点的原理
        - https://zhuanlan.zhihu.com/p/34003929
        - 软件断点
            - 一般情况下，调试器维护了一大组调试断点，找到加断点行所在的机器代码，在并把他们都换成了INT 3（二进制代码opcode是0xCC）。当程序执行到INT 3指令时，会引发软件中断。在被调度回来后，会都填回去，并通过现在的地址判断是到了那个断点。软件断点没有数目限制。
        - 硬件断点
            - X86系统提供8个调试寄存器（DR0~DR7）和2个MSR用于硬件调试。其中前四个DR0~DR3是硬件断点寄存器，可以放入内存地址或者IO地址，还可以设置为执行、修改等条件。CPU在执行的到这里并满足条件会自动停下来。缺点是只有四个
    - Lock、悲观锁、乐观锁
        - 悲观锁，如c#的lock 就是悲观锁
            - 总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁**（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）**
        - 乐观锁
            - 乐观锁不是锁，应该叫乐观机制。乐观的认为数据不会被其他线程修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的场景
            - 怎么实现？使用版本号机制和CAS算法实现
                - 版本号机制？一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。
                - CAS 是“CompareAnd Swap”的缩写，中文简称就是“比较并替换”，在CAS算法中，它使用了3个基本操作数：内存地址对应的值V，旧的预期值A（旧值），要修改的新值B（新值）。当且仅当预期值A和内存值V相同时，才将内存值修改为B，否则什么都不做，最后返回现在的V值。
        -  lock为什么要锁定一个参数，可不可锁定一个值类型？这个参数有什么要求
            - lock的锁对象要求为一个引用类型。她可以锁定值类型，但值类型会被装箱，每次装箱后的对象都不一样，会导致锁定无效
        - 为什么要lock?
            - 当不同的线程都需要访问某个资源的时候，就需要同步机制了，也就是说当对同一个资源进行读写的时候，我们要使该资源在同一时刻只能被一个线程操作，以确保每个操作都是有效即时的，也即保证其操作的原子性。lock是C#中最常用的同步方式
        - 如何避免死锁
        - lock的注意事项
            - lock的是引用类型的对象，string类型除外。字符串在CLR中会暂存在 内存中，如果有两个变量被分配了相同的字符串内容，那么这两个引用会指向同一块内存，实际锁定也就是同一个对象，这就会导致整个应用程序的阻塞
            - lock推荐的做法是使用静态的、只读的、私有的对象。如果该实例可以被公开访问，则 lock(this) 可能会有问题，因为不受控制的代码也可能会锁定该对象。这可能导致**死锁**
            - 保证lock的对象在外部无法修改才有意义，如果lock的对象在外部改变了，对其他线程就会畅通无阻，失去了lock的意义。
        - 死锁
            - 是什么？就是两个线程，都需要获取对方锁占有的锁，才能够接着往下执行，但是这两个线程互不相让，你等我先释放，我也等你先释放
            - C# 如何发现死锁
                - Monitor类，假设lock1，lock2 为死锁对，if (Monitor.TryEnter(lock1, TimeSpan.FromSeconds(5))) 这时候是尝试去获取lock1。因为lock1倍被支线程给获取了，那么获取不到，这时候等待5秒，5秒后获取不到就释放了lock2，这时候分支线程就继续运行。
            - 如何避免
                - 尽量避免大量嵌套的锁的使用
                - 使用锁的超时机制来避免对资源的长时间占用，
    - 静态链接 动态链接
        - 为什么代码无法同时在linux和windows下运行
            - 代码生成可执行文件,需要两个步骤,**编译和链接**
            - 代码在编译的时候会先编译成.o后缀目标文件,再将多个目标文件链接起来才能得到可执行文件
            - **链接**过程中，静态链接和动态链接就出现了区别,静态链接是在形成可执行程序前，而动态链接的进行则是在程序执行时
                - 静态链接的过程就已经把要链接的内容已经链接到了生成的可执行文件中，成为可执行文件的一部分.就算你在去把静态库删除也不会影响可执行程序的执行.该文件包含了运行时所需的全部代码。当多个程序都调用相同函数时，内存中就会存在这个函数的多个拷贝，这样就浪费了宝贵的内存资源;而动态链接这个过程却没有把内容链接进去，而是在执行的过程中，再去找要链接的内容，生成的可执行文件中并没有要链接的内容，所以当你删除动态库时，可执行程序就不能运行.动态链接生成的可执行文件要比静态链接生成的文件要小一些。
        - 动态链接
            - 动态链接库是一个可以被其它应用程序共享的程序模块，其中封装了一些可以被共享的例程和资源
            - 在windows 是.dll 在linux 是.so后缀
            - 优缺点
                - 即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本
                - ，更新也比较方便，更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍.当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标
                - 缺点:因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。
        - 静态链接
            - 是什么? 把要调用的函数或者过程链接到可执行文件中，成为可执行文件的一部分
            - 优缺点
                - 一是浪费空间，因为每个可执行程序中对所有需要的目标文件都要有一份副本
                - 更新比较困难，因为每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序
                - 优点:在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快
        - 总结
            - 如果你的系统上有多个应用程序都使用该库的话，就把它编译成动态库，这样虽然刚启动的时候加载比较慢，但是多任务的时候会比较节省内存；如果你的系统上只有一到两个应用使用该库，并且使用的API比较少的话，就编译成静态库吧，一般的静态库还可以进行裁剪编译，这样应用程序可能会比较大，但是启动的速度会大大提高
    - cpu调度算法
        - 
    - 并发 并行 同步 异步
        - 并发,计算机能够"同时"执行多项任务(不是真正的同时)
            - 实现并发方式
                - 单核计算机可以通过分配时间片的方式,让一个任务执行一段时间切换到另一个任务,交替运行,这个过程也成为线程的**上下文切换**
        - 并行
            - 多核,在不同的核心上真正的实现并行
        - 同步 异步
            - 同步 必须前一个任务执行完毕之后才可以进行下个任务,不存在并发与并行的概念
            - 异步
    - 单线程异步编程 vs 多线程编程
        - 优点
            - 无需考虑线程同步和资源竞争
        - 缺点
            - 回调地狱
                - 解决
                    - promise: 链式调用解决回调地狱
        - C# 实现异步编程 async await
            - async 定义异步函数
            - await 直接等待异步处理后返回的结果
        - 使用场景
            - 适合异步编程
                - 对于I/O密集的应用程序,如web应用的网络请求,数据库访问,文件系统读取等
                - 如果上述使用多线程编程,会有以下问题
                    - 浪费系统资源,因为每个线程大多数时间都是在等待I/O操作(数据库访问,文件系统读取等),线程占用额外内存,线程切换存在额外开销,资源竞争
            - 多线程编程
                - 适合计算量密集的应用:视频图像处理,科学计算等.可以让每个CPU核心发挥最大的功效

    - 进程间通信方式, 线程间通信方式
        - https://www.bilibili.com/video/BV1tv411p7WX 进程间通信方式
        - https://www.bilibili.com/video/BV1Eg411M7zi 管道是如何进行进程间通信的
        - 什么是进程通信
            - 进程通信（IPC），即Inter-ProcessCommunication，字面上理解就是进程之间的通信。
            > 举一个不同主机的进程通信例子:你电脑上打开一个网页，就能看到各种文字图片，这些图片是哪里来的？如何获取的？我们上面说打开的浏览器就是一个进程，那浏览器获取别处的图片资源就是一种通信的方式来拿到想要的东西的。浏览器向服务器发送请求获取资源就是一种靠套接字来进行的进程通信，这种通信通过一台主机的应用层端口以及Socket下发到运输层（TCP），再经过下面的网络层，数据链路层，物理层（这是计算机网络5层模型）传输到另一台机器的socket，最后服务器获取到该信息，实现进程间通信。一句话说，A主机的浏览器通过socket与另一台B主机的进程进行通信交流
        - 进程间通信方式
            - 管道模型
                - 什么是管道?
                    - 一个管道本质是两个文件描述符,来表示管道的读(fd0)与写(fd1)端
                - 一个进程创建一个管道只能给本进程用,管道如何实现进程间通信
                    - 子进程创建时候会对管道进行浅拷贝,指针引用同一个管道
                    ![管道通信](/img/in-post/post-js-version/pipeline.png)
                    - 有个问题,两个进程共用管道,都可以写 都可以读
                        - 解决:一个进程只读 一个进程只写,如果要都可以读写需要用到**双管道**
                - 匿名管道
                    - 什么是匿名管道,**将前一个命令的输出作为下一个命令的输入**,这种管道没有名字,用完就销毁了
                        - 如linux 命令行的 cat log.txt | grep 'ERROR' -A 5, 之中的"|"
                        - 意思是，在log.txt文件中，查找ERROR字符，并显示ERROR所在行的之后5行
                        - 本质:shell的A | B ,本质上是shell创建进程A,和进程B,管道是shell创建的,AB两个子进程共用这个管道
                - 命名管道
                    - FIFO，先进先出的通信方式
                    - 命名管道(Named Pipe)是服务器进程和一个或多个客户进程之间通信的单向或双向管道。不同于匿名管道的是命名管道可以在不相关的进程之间和不同计算机之间使用，服务器建立命名管道时给它指定一个名字，任何进程都可以通过该名字打开管道的另一端，根据给定的权限和服务器进程通信
            - 消息队列模型
            - 共享内存+信号量模型
                - 共享内存
                    - 优点:避免不必要的拷贝和传输,多个进程共享.缺点:进程不安全问题,脏数据等
                - 如何解决上述问题 => 信号量
                    - 一种避免进程竞争的方法, 限制一个资源只能被一个进程访问,进程访问串行化
            - 信号
                - 为什么?线上故障等突然情况,上述通信方式来不及处理响应
                - 是什么?24不间断的告警系统,一旦出现问题就通知到对应处理(网卡,硬盘,cpu等)放下手头工作,立即处理当前
            - socket
                - 网络之间的 进程与进程传输

    - 进程、线程、多线程、协程
        - 推荐文章:记得回来仔细再看一遍 https://blog.csdn.net/u012999985/article/details/49520773, https://www.cnblogs.com/anding/p/5301754.html
        - 进程是什么？
            - 进程是装入内存运行的程序段,是系统进行资源分配和调度的一个独立单位.(包括程序段,相关数据段和进程控制端PCB)
            > 我们的浏览器程序存放在C盘的某个位置，这时它只是硬盘上的程序。每次我们打开一个浏览器的时候，这个程序就会被装入内存中去，进行一系列初始化（进程控制块PCB的初始化，包括进程计数器，进程状态，CPU命令，寄存器等等）。此时我们看到了浏览器打开并显示网页，此时这就是一个运行中的进程，我们可以打开任务管理器看到许许多多运行的进程
            - Windows系统利用进程把工作划分为多个独立的区域，每个应用程序实例对应一个进程。
            - 调度方式?
                - 时间片轮转和先来先服务。进程有三种状态阻塞,就绪，运行。
        - 线程是什么？
            - 线程是进程的一个实体,是CPU运行调度的基本单位
            - 线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它与同一进程的所有线程共享相同的资源和内存（共享代码，全局变量，环境字符串等），使得线程间上下文切换更快、可以在同一地址空间内访问内存
            - 调度方式?
            - 引入线程的优点
                - 易于调度
                - 提高并发性
                - 开销小
                - 线程执行开销小,但不利于资源的管理和保护
                - 进程相反,且进程可以跨机器迁移
        - 进程、线程关系
            - 一个线程可以创建和撤销另一个线程
            - 同一个进程中的多个线程之间可以并发执行
            - 一个进程可以有多个线程、一个线程必须有一个父进程
        - 进程和线程的区别
            - 进程有独立的地址空间,一个进程崩溃后,在保护模式下不会堆其他进程产生影响.
            - 线程有自己的堆栈和局部空间,但没有单独的地址空间,一个线程死掉等于整个进程死掉,所以多进程的程序比多线程的程序健壮,但进程切换时候,耗费资源较大.对于要求同时进行并行且共享某些变量的并发操作,只能用线程,不能用进程
        - 为什么需要线程池
            - 线程是一个重量级的对象,应该避免频繁创建和销毁
        - 协程是什么？
            - 协程不是进程或线程，是某个主程序的一部分代码，该代码执行特定的任务并且与主程序中的其他代码相对独立
            - 与线程的区别
                - 多个线程相对独立，有自己的上下文，切换受系统控制；而协程也相对独立，有自己的上下文，但是其切换由自己控制
                - 协程避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任
    - 进程(资源分配的基本单位)
        - 进程控制块(PCB)：描述进程基本信息和运行状态
        - 线程同步实现机制
            - 临界区
            - 互斥区
                - 只有拥有互斥对象的线程才有权限区访问系统的公共资源,保证资源不会同事被多个线程访问
                > windows编程中互斥器、临界区区别:互斥器用于进程之间互斥，临界区用户线程之间互斥
            - 信号量
                - 为它允许多个线程同时访问同一个资源,但一般需要限制同一时刻访问此资源的最大线程数目
            - 事件
        - 调度
            - 先来先服务，短作业优先，最短剩余时间优先，时间片轮转，优先级调度，多级反馈队列
        - 通信
            - 管道，命名管道，消息队列，信号量，信号，共享内存，套接字
                - https://jerish.blog.csdn.net/article/details/48094323
        - 死锁
            - 产生条件以下四个，只要发生死锁必然都成立，只要一条不成立必然不会死锁
                - 互斥条件：一个资源每次只能被一个进程使用
                - 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放
                - 不剥夺条件：进程已获得的资源，在未使用完，不能强行剥夺
                - 循环等待条件：若干进程之间形成头尾相接的循环等待资源关系
            - 检测：资源分配图
            - 处理：剥夺资源，撤销进程
            - 避免：银行家算法
                - 在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的**安全性**，若分配不会导致系统进入不安全状态，则分配，否则等待。从而避免发生死锁。
    - 内存
        - 内存调度，页，虚拟地址和物理地址的转换、虚拟内存页面交换的过程
            - 页面置换：OPT，LRU，FIFO，Clock
        - C# 怎么动态分配内存
        - 内存分哪五大区
        - 内存管理方式
            - 块式管理,把主存分为一大块一大块,当所需的程序片段不在内存就分配一块主存空间.即使所需的程序片段只有几个字节也要分配一大块
            - 页式管理(最常用)
                - 把主存分为一页页,空间利用率比快式管理高很多
            - 段式管理
                - 分为一段段,比页空间小
                - 缺点:一个程序片段可能会被分为很多段,这样会浪费计算每一段的物理地址
            - 段页式管理,结合段式和页式管理的优点,把主存分成多干段,每个段分成多干页
        - 分段、分页
            - what?
                - 分页：将地址空间划分为固定大小的页
                - 分段：将地址空间划分为多个拥有独立地址空间的段
            - 区别
                - 分页是系统需要,大小固定,分段长度不固定由用户编写的程序决定
            - 计算机怎么管理内存（分段、分页)
        - 虚拟内存和物理内存的区别
            - 虚拟内存
                - https://www.bilibili.com/video/BV1xb4y1Z761
                - 是什么?
                - 为什么?
                - 怎么做?
                    - 单级页表 和多级页表 优缺点
                    - 反置页表
            - https://blog.csdn.net/lvyibin890/article/details/82217193
        - 内存碎片
            - 由于多次进行内存分配造成的.内存格式一般为:(用户使用段)(空白段)(用户使用段),空白段很小不能提供足够的空间
            - 内碎片
                - 进程占有这块存储块,系统无法利用它,需要进程结束系统才可以利用存储块
            - 外碎片
                - 空间太小,小到无法给任何程序分配的存储空间
        - 内存对齐
            - https://zhuanlan.zhihu.com/p/30007037
            - 举个例子
                - 理论上，32位系统下c语言，int占4byte，char占一个byte，那么将它们放到一个结构体中应该占4+1=5byte；但是实际上，通过运行程序得到的结果是8 byte，这就是内存对齐所导致的
            - what?
                - 现代计算机中内存空间都是按照byte划分的,理论上似乎对任何类型的变量的访问可以从**任何地址**开始,但是实际的计算机系统对基本类型数据在内存中存放的位置有**限制**,他们会要求这些数据的首地址的值是某个数K(通常它为4或8)的倍数,这就是所谓得内存对齐.
            - 为什么要做内存对齐
                - 一些平台对某些特定类型的数据只能从某些特定地址开始存取。比如有些架构的CPU在访问一个没有进行对齐的变量的时候会发生错误,那么在这种架构下编程必须保证字节对齐.其他平台可能没有这种情况，但是最常见的是如果不按照适合其平台要求对数据存放进行对齐，会在存取效率上带来损失
                - 内存存取粒度
                    - 尽管内存是以字节为单位，但是大部分处理器并不是按字节块来存取内存的.它一般会以双字节,四字节,8字节,16字节甚至32字节为单位来存取内存，我们将上述这些存取单位称为内存存取粒度
                    - 拿4字节存取粒度的处理器取int类型变量(32位系统)来说,该处理器只能从地址为4的倍数的内存开始读取数据
                    - **假设没有内存对齐**,数据可以任意存放,现在一个int变量存放在**地址1**开始的连续4个字节地址中,该处理器去取数据时,要先从0地址开始读取第一个4字节块,提出不想要的地址(0地址),然后从地址4开始读取下一个4字节块,同样剔除不要的数据(5,6,7地址),最后留下的两块数据合并放入寄存器,需要很多工作.
                    - **有内存对齐**,int类型数据只能存放在按照对齐规则的内存中,比容说0地址开始的内存,那么现在该处理器在取数据时,一次性就能将数据读出.
                - 合理的利用字节对齐可以有效地节省存储空间
                    - 在编程的时候要考虑节约空间的话,那么我们只需要假定结构的首地址是0,然后各个变量按照上面的原则进行排列即可,基本的原则就是把结构中的变量按照类型大小从小到大声明,尽量减少中间的填补空间.还有一种就是为了以空间换取时间的效率,我们显示的进行填补空间进行对齐:

                        ```c
                        struct A{
                            char a;
                            char reserved[3];//使用空间换时间,reserved成员对我们的程序没有什么意义,它只是起到填补空间以达到字节对齐的目的
                            int b;
                        }
                        ```
            - 内存对齐规则
                - 每个特定平台上的编译器都有自己的默认“对齐系数”（也叫对齐模数）。gcc中默认#pragma pack(4)，可以通过预编译命令#pragma pack(n)，n = 1,2,4,8,16来改变这一系数。
                - 内存对齐需要遵循的规则
                    - 结构体第一个成员的**偏移量**（offset）为0，以后每个成员相对于结构体首地址的 offset 都是**该成员大小与有效对齐值中较小**那个的整数倍，如有需要编译器会在成员之间加上填充字节。
                    - **结构体的总大小**为 有效对齐值 的**整数倍**，如有需要编译器会在最末一个成员之后加上填充字节。

                        ```c
                        //32位系统
                        #include<stdio.h>
                        struct
                        {
                            int i;    
                            char c1;  
                            char c2;  
                        }x1;

                        struct{
                            char c1;  
                            int i;    
                            char c2;  
                        }x2;

                        struct{
                            char c1;  
                            char c2; 
                            int i;    
                        }x3;

                        int main()
                        {
                            printf("%d\n",sizeof(x1));  // 输出8
                            printf("%d\n",sizeof(x2));  // 输出12
                            printf("%d\n",sizeof(x3));  // 输出8
                            return 0;
                        }
                        ```
            - 内存对齐可能带来的隐患
                - 如果从奇数边界去访问short型变量(2字节),不符合对齐的规定,在一些操作系统会带来报错,大多数类似操作影响操作
                - 内存冗余?
            - 什么时候取消对齐会带来好处呢?
        - 大小端
            - 是什么?
                - 大端为低地址到高地址,小端为高地址到低地址.比如数字0x12 34 56 78,大端:0x12  |  0x34  |  0x56  |  0x78,小端: 0x78  |  0x56  |  0x34  |  0x12. 大端模式和字符串的存储模式类似。
            - 场景
                - 采用小端方式进行数据存放利于计算机处理，因此计算机的内部处理较多用小端字节序。
                - 采用大端方式进行数据存放符合人类的正常思维，除了计算机的内部处理，其他的场合几乎都是大端字节序，比如网络传输和文件储存。
            - 优劣处
                - 各自优势便是对方劣势
                - 小端模式 ：强制转换类型时不需要调整字节内容，直接截取低字节即可
                - 大端模式 ：符号位的判定固定为第一个字节，容易判断正负。。

    - 磁盘调度：先来先服务，最短寻道时间优先，电梯算法
- C#
    - private，public，protected，internal
        - public：对任何类和成员都公开，无限制访问
        - private：仅对该类公开
        - protected：对该类和其派生类公开
        - internal：只能在包含该类的程序集中访问该类
    - 静态构造函数
        - 最先被执行的构造函数，且在一个类里只允许有一个无参的静态构造函数
        - 执行顺序：静态变量>静态构造函数>实例变量>实例构造函数
    - 装箱、拆箱
        
        ```csharp
        //csharp代码
        object objValue = 4;// 装箱操作将整形数字常量4装箱成引用类型object变量objValue
        int value = (int)ojbValue;//拆箱操作，将存储到堆上的引用变量objValue存储到局部整形值类型变量value中

        //ILd代码,装箱过程
        .locals init (
        [0] object objValue,
        [1] int32 'value'
        ) //上面IL声明两个局部变量object类型的objValue和int32类型的value变量
        IL_0000: nop
        IL_0001: ldc.i4.4 //将整型数字4压入栈
        IL_0002: box [mscorlib]System.Int32 //执行IL box指令，在内存堆中申请System.Int32类型需要的堆空间
        IL_0007: stloc.0 //弹出堆栈上的变量，将它存储到索引为0的局部变量中
        IL_0008: ldloc.0//将索引为0的局部变量（即objValue变量）压入栈
        IL_0009: unbox.any [mscorlib]System.Int32 //执行IL 拆箱指令unbox.any 将引用类型object转换成System.Int32类型
        IL_000e: stloc.1 //将栈上的数据存储到索引为1的局部变量即value
        ```

        - 装箱
            - 是什么？
                - 把值类型转换成引用类型
            - 过程？对值类型在堆中分配一个对象实例，并将该值复制到新的对象中
                - 新分配托管堆内存(大小为值类型实例大小加上一个方法表指针
                - 将值类型的实例字段拷贝到新分配的内存中
                - 返回托管堆中新分配对象的地址。这个地址就是一个指向对象的引用了
        - 拆箱
            - 是什么？
                - 把引用类型转换成值类型
            - 过程？
                - 检查对象实例，确保它是给定值类型的一个装箱值。将该值从实例复制到值类型变量中
        - 装箱拆箱区别？
            - 在装箱时是不需要显式的类型转换的，不过拆箱需要显式的类型转换
    - c#相关知识点：https://www.cnblogs.com/anding
    - ref、out
        - ref指定的参数在函数调用时必须先初始化，而out不用
        - out指定的参数在进入函数时会清空自己，因此必须在函数内部进行初始化赋值操作，而ref不用
        - 总结
            - ref可以把值传到方法里，也可以把值传到方法外；out只可以把值传到方法外
    - const, define
        - const
            - 一个关键字(修饰符)
            - 变量不允许改变,必须在定义的时候就给它赋初值
        - define
            - 宏定义, 则是一条预编译指令, 编译器在编译阶段会将所有使用到宏的地方简单地进行替换
        - 区别
            - const定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是象#define一样给出的是立即数，所以，const定义的常量在程序运行过程中只有一份拷贝，而#define定义的常量在内存中有若干个拷贝
            - const用于类成员变量的定义，同时const本身就是一个语言结构，而 define是一个函数，const在编译的时候要比define快很多
    - 协变、逆变
    - 重载、重写
        - 重写
            - 要求：（三大同）参数相同，方法名相同，返回值相同
            - 意义：是对基类中的虚方法进行重写，重写继承用的是父类的东西，则不仅得到父类的特征，同时也加入了自己的东西
            - 关键字：基类函数用virtual修饰,派生类用override修饰
            - 注意：不能重写非虚方法或静态方法；
        - 重载
            - 在同一作用域，可以存在相同的函数名，不同参数列表的函数，这组函数称为重载函数
            - 减少函数的数量，避免命名的污染，可应对不同的需求，针对同一母的不同情况
    - lambda
        - "Lambda表达式"是一个匿名函数
            - 优点：可以使代码更简洁
            - 缺点：容易产生闭包
        - 底层实现
    - 托管和非托管
        - 托管代码：是由公共语言运行库（CLR）执行的代码，而不是由操作系统直接执行。有关内存管理（内存申请，内存释放，垃圾回收之类的）全部都是.net的CLR来管理。
        - 非托管代码：直接编译成目标计算机码，由操作系统直接执行的代码，内存回收要继承IDisposable接口手动回收。
    - static关键字
        - https://www.bilibili.com/video/BV18K4y1u7k8
        - what? 常用的修饰符,它被用来控制变量的存储方式和可见性
            - 使用场景:需要一个数据对象为整个类而非某个对象服务,同时又力求不破坏类的封装性,即要求此成员隐藏在类的内部，对外不可见时，可将其定义为静态数据
        - 有什么作用,缺点
            - 作用
                - 可以节省内存，因为它是所有对象所公有的，因此，对多个对象来说，**静态数据成员只存储一处**，供所有对象共用, static 修饰的变量或函数不是跟着对象,而是跟着类走
                - 对静态数据成员的值更新一次，保证所有对象存取更新后的相同的值，这样可以提高时间效率
            - 特点:整个类型在程序运行期间只加载一次。 这样是对于那些经常使用的类型来说的， 那就不用每次使用前都先加载。效率高些
            - 缺点:
                - 对那些不常用的类型来说，如果是静态类型，那就要一直占用相当的内存；一直到程序停止。或者应用程序域被卸载。所以应该只对那些常用的类型定义成静态类型。
                - 静态类是密封的，因此不可被继承。静态类不能包含构造函数,不能override
                - 当类第一次被加载的时候，静态成员已经被加载到静态存储区，此时类的对象还有可能能没有创建，所以静态方法中不能调用类成员字段
                - this和base关键字都不能在静态方法中使用
        - 全局变量(global)、静态全局变量（static），静态局部变量、局部变量理解
            > **静态存储区**: 一定会存在的而且会永恒存在、不会消失，这样的数据包括常量、常变量（const 变量）、静态变量、全局变量等。静态 、常量、全局变量就是存放在静态存储区，他们在程序编译完成后就已经分配好了，生命周期持续至程序结束。
            **动态存储区**：函数形参变量（在调用函数时给形参分配存储空间），局部动态变量(auto register)，函数调用现场保护和返回地址等
            - 存储位置:全局静态变量和局部静态变量存在静态存储区;而局部变量存在于栈里
            - 作用范围：全局变量作用于整个源程序所包含的**所有源文件**中；静态全局变量与位置关联，仅作用于它所在的**源文件**中；局部变量作用于其定义的函数中
                - 使用:当变量仅在某个文件中使用，最好将其定义为静态变量; 若全局变量仅在某个函数中使用最好将其定义为局部变量
            - 生命周期:
                - 静态变量存储在静态存储区中，不需要实例化对象；在程序一开始就给它分配空间，直到程序结束；如果未初始化将被赋值为0；
                - 全局变量在对象的生命周期里存在，如果对象被销毁了，这个普通变量将会消失；而静态全局变量是在类的生命周期里存在；
        - 回收
            - 垃圾回收机制不能回收静态变量,但是静态变量所引用的对象会被gc回收
            - 什么时候销毁
                - 静态变量在类被卸载的时候销毁
                - 类什么时候被销毁
                    - 在进程结束的时候
        - 静态类、单例类的
            - 区别
                - 单例模式会提供给你一个全局唯一的对象，静态类只是提供给你很多静态方法，这些方法不用创建对象，通过类就可以直接调用
                - 单例模式的灵活性更高，方法可以被override，因为静态类都是静态方法，所以不能被override
                - 如果是一个非常重的对象，单例模式可以懒加载，静态类就无法做到
                - 静态方法中产生的对象，会随着静态方法执行完毕而释放掉，而且执行类中的静态方法时，不会实例化静态方法所在的类。如果是用singleton,   产生的那一个唯一的实例，会一直在内存中，不会被GC清除的
            - 怎么让单例模式的静态类延迟加载(懒加载)
                - 饿汉模式:立即加载，一般情况下再调用getInstancef方法之前就已经产生了实例，也就是在类加载的时候已经产生了

                    ```csharp
                    //饿汉模式
                    class SingletonHungary {
                        private static SingletonHungary singletonHungary = new SingletonHungary();
                        //将构造器设置为private禁止通过new进行实例化
                        private SingletonHungary() {

                        }
                        public static SingletonHungary getInstance() {
                            return singletonHungary;
                        }
                    }

                    // 懒汉模式--后实例化,线程不安全,需要加锁
                    public class Singleton
                    {
                        private static Singleton _singleton;
                        private Singleton()
                        {

                        }
                        public static Singleton GetInstance()
                        {
                            if (_singleton == null)
                            {
                                _singleton = new Singleton();
                            }
                            return _singleton;
                        }
                    }
                    ```

            - 什么时候选静态类,什么时候选单例
                - 当你需要面向对象的能力时（比如继承、多态）时，选用单例类，当你仅仅是提供一些方法时选用静态类。
    - foreach实现原理
    - 死锁的原理和检测避免预防
    - sizeof
        - 用于获取 值类型 的字节大小。
        - 对于所有其他类型（包括 struct），sizeof 运算符只能在不安全代码块中使用。
        - sizeof只适用于值类型，并且需要在unsafe上下文环境中使用
    - C# List源码解析
        - http://www.luzexi.com/2018/07/06/Unity3D%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E9%98%B6%E4%B8%BB%E7%A8%8B-CSharp%E8%A6%81%E7%82%B9%E6%8A%80%E6%9C%AF1
        - 思考
            - 容量扩增是加倍,可以用其他方式吗
                - 每次追加固定大小的容量 elem = new T[_capacity += INCREMENT]
    - C# Dictionary源码解析
        - https://www.cnblogs.com/Jaysonhome/p/12823088.html
        - 查找原理
            - /对应的桶拿到该桶位置最近一次的实体的idx， 遍历桶位置的单链表，如果对应的key和参数key相等，则return
    - c#中，ArrayList和list，dictionary和hashtable区别，dictionary的底层实现原理
        - https://www.cnblogs.com/yiyi20120822/p/11429137.html
        https://www.cnblogs.com/TiestoRay/p/4891026.html
        - Dictionary与Hashtable
            - 数据结构上来说都属于Hashtable, 都是对关键字（键值）进行散列操作,将关键字散列到Hashtable的某一个槽位中去，不同的是处理碰撞的方法
            > Dictionary采用链表法处理碰撞,通过Hash算法来碰撞到指定的Bucket上，碰撞到同一个Bucket槽上所有数据形成一个单链表。
            ```
            int hashCode = comparer.GetHashCode(key) & 0x7FFFFFFF;
            //将HashCode的返回值转化为数组索引
            int bucketIndex = hashCode % buckets.Length;
            ```
            HashTable采用开放寻址法方法中的双重散列处理碰撞
            - dictionary
                - 有泛型优势（类型安全，性能更好），对于值类型，不存在装箱和拆箱的性能损耗
                - 读取速度快（体现在单条数据上）
                - 容量利用更充分
                - 非线程安全,多线程必须人为使用 lock 语句进行保护,  效率大减.
                - 有序（遍历时输出的顺序就是加入的顺序）
            - hashtable
                - 适合多线程
                - 通过静态方法Synchronize方法可获得完全线程安全的类型
                - 无序
        - List与Dictionary
            - List有点类似于Dictionary。二者都具有使用泛型的优点(联想到ArrayList)，Dictionary没有在内存中移动后续元素的性能开销。
            > ArrayList是可变长数组，你可以将任意多的数据Add到ArrayList里面。其内部维护的数组，当长度不足时，会自动扩容为原来的两倍。但是ArrayList也有一个缺点，就是存入ArrayList里面的数据都是Object类型的，所以如果将值类型存入和取出的时候会发生装箱、拆箱操作(就是值类型与引用类型之间的转换)，这个会影响程序性能。在.Net 2.0泛型出现以后，就提供了List<T>。List<T>是ArrayList的泛型版本，它不再需要装箱拆箱，直接取，直接用
            - List是在数组的基础上做的封装,本质是有序的动态数组，遍历查询更快(数据较多时)，Dictionary单条查询更快
            > 同样是集合，为什么性能会有这样的差距。我们要从存储结构和操作系统的原理谈起。首先我们清楚List<T>是对数组做了一层包装，我们在数据结构上称之为线性表，而线性表的概念是，在内存中的连续区域，除了首节点和尾节点外，每个节点都有着其唯一的前驱结点和后续节点。我们在这里关注的是连续这个概念。而HashTable或者Dictionary，他是根据Key和Hash算法分析产生的内存地址，因此在宏观上是不连续的，虽然微软对其算法也进行了很大的优化。由于这样的不连续，在遍历时，Dictionary必然会产生大量的内存换页操作，而List只需要进行最少的内存换页即可，这就是List和Dictionary在遍历时效率差异的根本原因。
            >> 在这里我们除了刚才的遍历问题，还要提到Dictionary的存储空间问题，在Dictionary中，除了要存储我们实际需要的Value外，还需要一个辅助变量Key，这就造成了内存空间的双重浪费。而且在尾部插入时，List只需要在其原有的地址基础上向后延续存储即可，而Dictionary却需要经过复杂的Hash计算，这也是性能损耗的地方。
        - 数组和list对比
        - map 和 hashmap 区别
        - tree了解吗？红黑树知道吗？说说你理解的红黑树
    - 为何尽量不要用foreach
        - foreach,本质上是Enumerator 这个结构，每次获取迭代器时，Enumerator 每次都是被new出来，如果大量使用迭代器的话，比如foreach就会造成大量的垃圾对象
    - CLI、CIL、JIT、Mono
        - C#编译和执行都要依赖CLI(公共语言基础结构)，c#生成中间语言指令，也就是公共中间语言（CIL）
        - CLI是理解C#程序的执行环境以及C#如何与其他程序和库（甚至是用其他语言写的）进行无缝交互的一个重要规范
        - Mono是开源的跨平台的CLI实现。
        - C#通过C#编译器（如 Mono），编译称公共中间语言（CIL），将CIL转换成处理器能执行的指令。
        - “虚拟执行系统”负责管理C#程序的执行，它能理解CIL语句，并将其编译程机器码，这个组件称为即时编译器(JIT)

    - 什么是.NET？什么是CLI？什么是CLR？IL是什么？JIT是什么，它是如何工作的？GC是什么，简述一下GC的工作方式？
        - .NET是微软公司下的一个跨语言开发平台
        - CLR的结构的结构
            - CTS:通用类型系统，将各种语言中的数据类型转换成统一的类型。
            - CLS:通用语言规范，获取各种语言转换成统一的语法规范。
            - JIT:实时编译器（即时编译器）用于将转换之后的语言编译为二进制语言，交给CPU执行。
        - 如何工作
            - 各种语言（c#,F#,j#等对应的源程序）———> 经过CTS，CLS第一次编译 ———> 统一规范语言（中间语言）MSIL(.EXE,.DLL)———> JIT第二次编译 ———> 二进制语言 ———> 运行在CPU中
    - 类（class）和结构（struct）的区别是什么？它们对性能有影响吗？.NET BCL里有哪些是类（结构），为什么它们不是结构（类）？在自定义类型时，您如何选择是类还是结构？
        - 区别
            - Class属于引用类型，是分配在内存的堆上的；
            - Struct属于值类型，是分配在内存的栈上的；不能从另外一个结构或者类继承，本身也不能被继承；没有默认的构造函数，但是可以添加构造函数；可以不使用new 初始化
    - 在.NET程序运行过程中，什么是堆，什么是栈？什么情况下会在堆（栈）上分配数据？它们有性能上的区别吗？“结构”对象可能分配在堆上吗？什么情况下会发生，有什么需要注意的吗？
    - 泛型的作用是什么？它有什么优势？它对性能有影响吗？它在执行时的行为是什么？.NET BCL中有哪些泛型类型？举例说明平时编程中您定义的泛型类型。
    - 异常的作用是什么？.NET BCL中有哪些常见的异常？在代码中您是如何捕获/处理异常的？在“catch (ex)”中，“throw”和“throw ex”有什么区别？您会如何设计异常的结构，什么情况下您会抛出异常？
    - List<T>和T[]的区别是什么，平时你如何进行选择？Dictionary<TKey, TValue>是做什么的？.NET BCL中还有哪些常用的容器？它们分别是如何实现的（哪种数据结构）？分别是适用于哪些场景？
    - 抽象类和接口有什么区别？使用时有什么需要注意的吗？如何选择是定义一个“完全抽象”的抽象类，还是接口？什么是接口的“显式实现”？为什么说它很重要？
        - 请描述Interface与抽象类之间的不同
            - 相同点
                - 都可以被继承
                - 都不能被实例化
                - 都可以包含方法的声明
            - 不同点
                - 抽象类被子类继承；接口被类实现
                - 抽象类只能被单个类继承；接口可继承接口，并可多继承接口
                - 抽象类可以做方法声明，也可做方法实现；接口只能做方法声明
                - 具体派生类必须覆盖(override)抽象基类的抽象方法；派生类必须实现接口的**所有方法**
                - 抽象类是一个不完整的类，需要进一步细化；接口是一个行为规范
                - 抽象类中的虚方法或抽象方法必须用public修饰；接口中的所有成员默认为public，不能有private修饰符
    - 虚方法和抽象方法
        - 虚方法:可以在基类的派生类中对虚函数进行**重新定义**
            - 如何实现?虚函数本质是一个类的虚函数地址表实现,指明了实际调用的函数
            - 什么函数不能声明为虚函数
                - 静态成员函数.调用静态成员函数不要实例,但调用虚函数需要从一个实例中指向虚函数表的指针以得到函数的地址,需要实例,冲突了.
                - 构造函数,析构函数可以为虚函数,且通常为虚函数
            - 函数调用是在编译时确定还是运行时确定的？如何确定调用哪个函数？
                - 运行时确定，通过查找虚函数表中的函数地址确定
            - 虚函数是存在类中还是类对象中（即是否共享虚表)?
                - 存在类中，不同的类对象共享一张虚函数表(为了节省内存空间)。
            - 在(基类的)构造函数和析构函数中调用虚函数会怎么样？
                - 从语法上讲，调用没有问题，但是从效果上看，往往不能达到需要的目的（不能实现多态）；因为调用构造函数的时候，是先进行父类成分的构造，再进行子类的构造。在父类构造期间，子类的特有成分还没有被初始化，此时下降到调用子类的虚函数，使用这些尚未初始化的数据一定会出错；同理，调用析构函数的时候，先对子类的成分进行析构，当进入父类的析构函数的时候，子类的特有成分已经销毁，此时是无法再调用虚函数实现多态的。
            - 构造函数是否可以作为虚函数
                - 不可以
                - 因为构造函数是，需要确定对象的类型，而虚函数是在运行期间确定类型的，因此编译器无法知道是要构造基类对象，还是构造派生类的对象，因此构造函数不可以是虚函数
                - 虚函数的执行依赖于虚函数表，而虚函数表是在构造函数中进行初始化工作的，即初始化vptr，指向正确的虚函数表。在构造期间，虚函数表还没有生成，因此不能将构造函数设为虚函数

            - 都声明为虚函数可以吗? 需要内存中多维护一个虚函数表,额外开销.
        - 抽象方法是只有方法名称，没有方法体，即没有方法的具体实现，子类必须重写父类抽象方法才能实现具体功能；虚函数有方法名称也也有方法体，但是子类可以覆盖，也可不覆盖。
        - 抽象方法是一种强制派生类覆盖的方法，否则派生类将不能被实例化。
        - 抽象方法只能在抽象类中声明，虚方法不是。
        - 派生类必须重写抽象类中的抽象方法，虚方法则不必要。
    - 多态的原理
        - 通过基类引用或指针调用一个虚函数时，根据对象是基类对象还是派生类对象，调用相应的基类或派生类的函数
    - 如何阻止一个类被实例化
        - 抽象类
        - 构造函数声明为private
    - 浅克隆与深克隆
        - 浅克隆
            - 如果原型对象的成员变量是值类型，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象
            - 通过实现ICloneable接口的Clone()方法，并调用MemberwiseClone()方法来实现浅克隆
        - 深克隆
            - 无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象
            - C#语言中，如果需要实现深克隆，可以通过序列化(Serialization)等方式来实现
            - lua
                ```lua
                function DeepCopy(t)
                    if nil == t then return nil end
                    local result = ()
                    for k, v in pairs(t) do
                        if "table" == type(v) then
                            result[k] = DeepCopy(v)
                        else
                            result[k] = v
                        end
                    end
                    return result
                end

                ```
    - property与attribute的区别
        - property是属性，用于存取类的字段
        - attribute是特性，用来标识类，方法等的附加性质。
    - sealed
        - 修饰掉那些确保不会被继承的类或函数。
    - 字符串是引用类型类型还是结构类型？它和普通的引用类型相比有什么特别的地方吗？使用字符串时有什么需要注意的地方？为什么说StringBuilder比较高效？在连接多个字符串时，它无论何时都比直接相加更高效吗？
    - 如何高效地进行数组复制？“二维数组”和“数组的数组”有什么区别？在使用双重循环遍历一个二维数组时，如何选择内外层的遍历顺序？
    - 什么是元编程，.NET有哪些元编程的手段和场景？什么是反射？能否举一些反射的常用场景？有人说反射性能较差，您怎么看待这个问题？有什么办法可以提高反射的性能吗？
        - 反射Reflection
            - 动态获取程序集信息。
    - 委托是什么？匿名方法是什么？在C# 3.0中，Lambda表达式是什么？扩展方法是什么？LINQ是什么？您觉得C# 3.0中还有哪些重要的特性，它们带来了什么优势？BCL中哪些类库和这些特性有关？您平时最常用哪些？
        - 委托是一个类，它定义了方法的类型，使得可以将方法当作另一个方法的参数来进行传递，这种将方法动态地赋给参数的做法，可以避免在程序中大量使用If-Else(Switch)语句，同时使得程序具有更好的可扩展性。
    - C#的委托是什么？有何用处？
        - 委托类似于一种安全的指针引用，应当做类来看待而不是一个方法，相当于对一组方法的列表的引用。
	    - 用处：使用委托使程序员可以将方法引用封装在委托对象内。然后可以将该委托对象传递给可调用所引用方法的代码，而不必在编译时知道将调用哪个方法。与C或C++中的函数指针不同，委托是面向对象，而且是类型安全的。
    - event 关键字有什么用
        - event关键字的作用，为了限制委托的调用条件，使之只能在外部进行-=、+=操作不能调用，但可以能在类内部调用。
        - 委托与事件的区别是什么
            - 委托可以把一个方法作为参数传入另一个方法，可以理解为指向一个函数的引用
            - 事件是一种特殊的委托。
    - 工作之外您看哪些技术相关的书、网站、社区、项目等等？您还接触哪些.NET以外的技术，能和.NET或.NET中有针对性的部分做个对比吗？

- unity
    - 常见生命周期
        - Reset,called in the Editor when the script is attached or reset
        - Awake
        - OnEnable
        - Start, 脚本只会执行一次
        - FixedUpdate 从这里到OnCollisionXXX都是属于物理循环，可能在一帧内循环多次。
        - yield WaitForFixedUpdate
        - OnTriggerXXX
        - OnCollisonXXX
        - OnMouseXXX
        - Update
        - yield null
        - yield WaitForSeconds 会受到Time.timeScale的影响，当Time.timeScale为0时，协程将永远不会被恢复。如果一定要用真实时间可以用WaitForSecondsRealtime，它不会受到Time.timeScale的影响
        - LaetUpdate
        - yield WaitForEndOfFrame
        - OnApplicationPause
        - OnGUI 一帧内可能循环多次
        - OnDisable，仅在脚本禁用的时候
        - OnDestory
        - OnApplicationQuit
    - 特殊目录
        - resources
            - 什么是Resources System
                - 在项目中的躲过Resources文件夹下存放一个或多个资源文件夹,并且支持unity提供的api对objects进行加载和卸载
            - 如果resources中的文件结构复杂,内容多,会有什么影响
                - 每个文件都有大小,在Resources文件夹下的资源都会被编译到包体中
                - 资源管理上的成本会增加
                - 构建时间增加(打包)
                    - Resources文件夹下的Assets和Objects都会被合并到一个序列化文件中去,序列化文件的合并会随着Resources中的资源增加而增加
                    - 查找数据结构是平衡搜索树,构建时间是O(nlogn),索引的加载时间随着"对象"数量增长而增长
                    - 序列化文件?
                        - 该索引包含一个序列化的查找树,该树通过对象的名称解析出对象对应文件的**GUID(meta文件)和localID(资源本身文件)**
                - 影响游戏的启动时间
                    - 启动时,对项目中所有需要立刻用到的对象进行**Instance Id实例化(如内置scene中引用),以及Resources文件夹下包含的所有对象都需要实例化Instance Id**
                    - Instance Id就是通过GUID和localID之前的映射得到的
            - 什么资源推荐放在Resources下
                - 该内容在整个游戏生命周期中存在
                    - 如MonoBehaviour singletons
                    - ScritableObjects 配置文件
                    - Loading Prefab
                - 资源所占内存小
                - 资源不会热更新
    - 插值Lerp运用
        - https://www.cnblogs.com/unity3ds/p/5737152.html
    - 如果不让你用UI组件，在unity中怎么展现一张图片？
    - 高速移动的物体发生collider穿透怎么解决
    - UGUI 和 NGUI有什么区别
    - UGUI的Sprite和Texture关系
        - UGUI开发时使用的是Sprite对象,Sprite只是在Texture上又封装了一层数据结构,包含Sprite大小以及九宫格区域.
    - 描述一下UGUI的渲染过程？如一个界面是ugui是如何展示出来的
    - ugui如何减少drawcall？可以联想到ugui造成drawcall源码原理
    - 讲讲项目中的事件触发器
    - overdraw
        - https://zhuanlan.zhihu.com/p/66919699
    - unity 如何做版本管理
        - 比如 客户端是1.1.1版本，服务器是2.2.2版本，更新流程是什么
        - 比如 2.0 到2.1到2.2 版本是全量、增量的吗？能从2.0直接到2.2吗？ 增量和全量有什么区别？ 2.0=>2.1=>2.2 会有可能有多余的资源下载
    - untiy游戏 C#和lua是如何交互的？
    - Unity 与Mono和.Net的关系
        - .Net拥有跨语言，跨平台性。Unity引擎需求也是需要跨平台，支持多语言（C#，Js，Boo）。就参考微软开发.Net Core的概念，于是，推出了Mono.
        - Unity之所以能跨平台是因为有通用中间语言（CIL），CIL是一种可读性比较低的面向对象的语言。它是基于堆栈的，与具体CPU中的寄存器无关。CIL运行在Mono运行时（虚拟机）上，其实它能运行在任何支持CLI(通用语言基础结构)的平台上，包括.NET与Mono，所以能实现跨平台。即 虽然IOS系统不能运行.exe文件，但是mono虚拟机可以，所以可以跨平台。
    - mvc 是什么？描述一下如何运用
    - 背包一滚动 就卡?
    - mask mask2d 区别
    - 界面切换？
        - 把被覆盖的界面 SetActive(False)，但发现后续 SetActive(True) 的时候会有 GC.Alloc 产生。这种情况下，希望既降低 Batches 又降低 GC Alloc 的话
            - 尝试通过添加一个 Layer 如 OutUI， 且在 Camera 的 Culling Mask 中将其取消勾选（即不渲染该 Layer）。从而在 UI 界面切换时，直接通过修改 Canvas 的 Layer 来实现“隐藏”。但需要注意事件的屏蔽，禁用动态的 UI 元素等等。这种做法的优点在于切换时基本没有开销，也不会产生多余的 Draw Call，但缺点在于“隐藏时”依然还会有一定的持续开销（通常不太大），而其对应的 Mesh 也会始终存在于内存中（通常也不太大）
            - 我们不建议通过 Instantiate/Destroy 来处理切换频繁的 UI 界面，而是通过 SetActive(true/false)，甚至是直接移动 UI 的方式，以避免反复地造成堆内存开销。
    - Active/Deactive 的开销
        - C#层到Native层的穿梭调用速度比C#层内的速度慢
        - UI元素的变化导致所在的Canvas变化，触发函数Canvas.SendWillRenderCanvases()与Canvas.BuildBatch()造成高耗时
        - UI元素的网格顶点数组改变会造成堆内存分配，触发GC，导致耗时（不过对UI元素进行位置移动不会造成堆内存分配）
        - 怎么优化
            - 在C#层设置变量来标识相应的GO处于Active还是非Active状态，避免对Active的对象进行SetActive(true)，避免对非Active的对象进行SetActive(false)
                - 对Active进行SetActive(true)时，“底层”会进行判断，但调用的时候，就已经是从C#层调用底层，导致开销较高。在C#层判断好，就避免了让底层判断
            - 将要频繁变化的UI元素与不频繁变化的UI元素放在不同的Canvas中，减少UI元素变化时的耗时
            - 通过将UI元素的坐标移动到Canvas的范围之外的方法来显示与隐藏，避免SetActive的耗时以及SendWillRenderCanvases的耗时
            - .经测试，对Component进行enabled = false的操作比对GO进行SetActive(false)的操作耗时低
            - 通过添加CanvasGroup组件设置透明度的方式来进行显示与隐藏
    - 模拟unity管理GameObject上Mono组件的生命周期？
        - Mono是什么？包含了实现特定脚本函数的组件类
        - 组件时什么？组件在unity中是如何实现？gameobjet是组件的容器
        - 生命周期是什么？unity 是如何管理生命周期，本质上通过遍历
        - unity 引擎是什么？管理项目中的资源+程序运行中的游戏对象树
    - Unity中Image拉伸旋转后出现严重锯齿，如何能减少锯齿感呢
        - cavas的RenderMode 修改为 使用Screen Space-Camera的方式
        - 考虑让ui直接出图成斜的，overdraw高一些，不过不用抗锯齿了
        - 有取巧的方式，就是让美术把图片四边留一部分透明区域
    - 跨平台编译需要注意哪些问题
    - 帧动画底层原理
    - 王者荣耀人物周围一群小怪，你放技能如何判断伤害打到了哪个小怪身上。
    - 王者荣耀摇杆，如果网络差的情况下一顿操作，在网络恢复正常的情况下会把所有的操作发送到服务器，服务器会下发所有的同步，会导致游戏不可控影响游戏体验,怎么解决
        - 有人建议是快速追帧
        - 帧同步？ https://zhuanlan.zhihu.com/p/66582899
    - 线上bug怎么看。代码调用堆栈
    - 打动态图集有什么规范？图片的压缩格式用什么？背包商店的图片怎么打成图集是最优的？动态图集的大小是怎么设定的？使用动态图集有什么缺点？图集能不能做缓存?缓存的策略是什么？
        - 图集打包怎么分类
            - 按业务功能的预制，寻找依赖，收集所有预制引用的图片
            - 如果有多个预制使用了同一张图片，我们就把它扔到common文件夹
            - 让图集尽量紧凑，没有太多空白，尽量让图集处于2的n次方大小
            - 设计UI时要考虑重用性，如一些边框、按钮等，这些作为共享资源，放在1~3张大图集中，称为重用图集；其它非重用UI按照功能模块进行划分，每个模块使用1~2张图集，为功能图集；对于一些UI，如果同时用到功能图集与重用图集，但是其功能图集剩下的“空位”较多，则可以考虑将用到的重用图集中的元素单独拎出来，合入功能图集中，从而做到让UI只依赖于功能图集。也就是通过一定的冗余，来达到性能的提升
    - ui框架实现了什么功能？如何管理面板层级关系，遮挡关系，互斥关系？如何做缓存策略？
    - 如果ui界面打开比较慢，有可能有什么问题。
        - 加载UI预制的时候，如果把特效放到预制里，会导致加载非常耗时
        - UI和特效（粒子系统）的加载开销在多数项目中都占据较高的CPU耗时。UI界面的实例化和加载耗时主要由以下几个方面构成：
            1. 纹理资源加载耗时，UI界面加载的主要耗时开销，因为在其资源加载过程中，时常伴有大量较大分辨率的Atlas纹理加载，ui纹理优化，如格式、图集分表率等
                - 优化ui纹理和图集
            2. UI网格重建耗时，UI界面在实例化或Active时，往往会造成Canvas（UGUI）或Panel（NGUI）中UIDrawCall的变化，进而触发网格重建操作。当Canvas或Panel中网格量较大时，其重建开销也会随之较大。
            3. UI相关构造函数和初始化操作开销，这部分是指UI底层类在实例化时的ctor开销，以及OnEnable和OnDisable的自身开销。
            - 2和3主要为引擎或插件的自身逻辑开销，因此，我们应该尽可能避免或降低这两个操作的发生频率
                - 在内存允许的情况下，对于UI界面进行缓存。尽可能减少UI界面相关资源的重复加载以及相关类的重复初始化
                - 根据UI界面的使用频率，使用更为合适的切换方式。比如移进移出或使用Culling Layer来实现UI界面的切换效果等，从而降低UI界面的加载耗时，提升切换的流畅度。
        - 第一次加载慢，什么问题？
        - 第二次加载慢？
    - ui框架 能不能无限一直打开界面
    - 一个界面打开的时候ui动画应该怎么做效率最高？
    - 断线重连? 对于帧同步、状态同步处理方法是不一样的
        - 状态同步需要恢复游戏的状态数据。
        - 帧同步需要从第一帧开始追帧到当前最新游戏帧。如何实现？
    - 战斗系统怎么实现？
        - 如果放了一个技能，如何判定对方是否收到伤害？
        - 收到伤害如何做飘出伤害文字？伤害文字怎么优化？
    - 行为树和状态机的区别
    - 行为状态机和指令状态机
    - 请简述GC（垃圾回收）产生的原因，并描述如何避免
        - 当用new创建对象时，当可分配的内存不足GC就会去回收未使用的对象，但是GC的操作是非常复杂的，会占用很多CPU时间，对于移动设备来说频繁的垃圾回收会严重影响性能。下面的建议可以避免GC频繁操作。
            - 减少用new创建对象的次数，在创建对象时会产生内存碎片，这样会造成碎片内存不法使用；
            - 使用公用的对象（静态成员，常量），但是不能乱用，因为静态成员和常量的生命周期是整个应用程序；
            - 在拼接大量字符串StringBuilder;并设置初始大小如：StringBuilder sbHtml = new StringBuilder (size);
            - 使用object pool(对象池)；
            - 5）定时进行主动GC操作，如场景切换；
            - 6）调用 StartCoroutine()会产生少量的内存垃圾，因为unity会生成实体来管理协程，yield在协程中不会产生堆内存分配，但是如果yield带有参数返回，则会造成不必要的内存垃圾；
    - Unity中Lua造成的堆内存泄露问题
        - 当Unity的Object被销毁时，并没有机会通知到Lua。此时，如果引用该对象的Lua变量没有通过LuaGC掉（LuaGC会通知ToLua的字典清理对应数据），则这个已经被Destroy的对象就一直被引用住了。项目中的Lua变量没有被LuaGC掉的情况有以下几种情况:
            - Lua对象是全局变量，直接放在_G中
                - 禁止定义全局变量，给现有的全局变量前加载local声明。可以使用一些Lua静态语法检查的手段，如Luacheck来检查。
            - Lua对象被一些全局的Table引用。
                - 我们每个UI面板都对应MVC结构，用了面向对象的概念。其中view在面板关闭时会直接置空，但Ctrl和Model都不会，它们都放在一个全局的管理类（Table）。当Model中持有了面板上的对象时，会出现对象销毁了，但Model中的变量不为空的情况。
            - Lua对象的function字段被赋值给了C#的事件/委托。
                - 比如UI控件的按钮点击事件。在LuaGC时，发现C#对象对其有引用，GC不掉。导致Lua中的对象通过Tolua引用住了C#对象，而C#对象又通过ToLua引用Lua对象。
                    - 对于每一个提供给Lua注册事件/委托的C#类，都继承一个IClear接口，该接口内实现清理事件/委托。
                    - 在MonoBehavior的OnDestroy函数内，调用IClear的接口。但要注意的是，这并不能保证所有的组件都是清理完毕，因为deactvie状态的组件，是不会触发OnDestroy的。因此需要手动的调用清理。
                    - 提供一个清理GameObject Lua事件/委托的接口，该接口会找到GameObject上所有继承于IClear接口的类，执行清理操作。需要手动清理的GameObject都需要调用该函数。
                    - 提供一个新的Destroy函数全局替换Unity原生的销毁GameObject接口。该函数在做真正销毁前，通过（3）清理所有注册的事件/委托。
    - 简述值类型与引用类型的区别
        - 值类型存储在内存栈中，引用类型数据存储在内存堆中，而内存单元中存放的是堆中存放的地址。
        - 值类型存取快，引用类型存取慢。
        - 值类型表示实际数据，引用类型表示指向存储在内存堆中的数据的指针和引用。
        - 栈的内存是自动释放的，堆内存是.NET中会由GC来自动释放。
        - 值类型继承自System.ValueType,引用类型继承自System.Object。
    - 结构体和类有何区别
        - 结构体：是值类型，结构体对象分配在堆栈上而不是堆上。类：是引用类型，对象分配在堆上。
        - 结构体：不能从另外一个结构或者类继承，本身也不能被继承；类： 完全可扩展的，除非显示的声明sealed，否则类可以继承其他类和接口，自身也能被继承。
        - 结构体：不包含显式默认构造函数；没有析构函数，不能继承；不能有protected修饰符，可以不使用new初始化，在结构中初始化实例字段是错误的；类： 有默认的构造函数，有析构函数，可以使用abstract和sealed，有protected修饰符，必须使用new初始化。

    - 性能优化
        - GC
            - 垃圾是怎么产生的？
            - 为什么要进行垃圾收集？
            - 垃圾收集放在什么时间点比较合适？
            - 如何成代码设计的角度避免垃圾的产生？
        - 内存管理
            - 在C#中分堆内存 栈内存，有什么区别？
            - 内存中还分成mono管理（托管堆）的内存、资源内存、代码内存管理。
            - drawcall 优化
            - 耗电问题怎么优化
    - Unity性能要点参考标准
        - CPU:主要看帧数，如果多数帧在预期中可忽略，对于重点卡帧的点进行优化
        - 内存：
            - Reserved Memory：总体内存，对于低端机总体内存尽量控制在150M以内
            - Reserved Mon Memory：堆内存，建议控制在50M以内； 对于堆内存较高的可以检测是都具有较大的Container、Array、List、Dictionary等容器存在，比如缓冲池，控制其开辟的大小
        - 资源加载：主要是场景切换时对象的创建和销毁，对于纹理可将其由RGBA32和RGBA16转换为ETC1进行加载即可以降低App和内存的大小又可以提高加载速度，进而提高切换场景的速度，场景中的网格数据可以进一步压缩减少不必要的数据占用
        - 用缓存池来进行缓存减少频繁使用对象的创建次数
        - 可以将Shader统一分离打包成AssetBundle，在游戏开始时加载进来，Shader体积较小，可常驻内存。
        - 纹理内存低端机建议控制在50M以内，推荐使用格式Android：ETC1，iOS：PVRTC；
        - 代码的CPU占用 Camera.Rende，MonoBehaviour.Update，Animator.Update & MeshSkinning.Update 建议关闭GPU Skinning
        - DrawCalls的优化，尽量做到分层合批，光效的粒子Order in layer的设置，材质相同的发射器使用相同的 Order in layer；避免材质打断，还有UI资源分块打包成图集
        - 如何优化内存
            - 将暂时不用的以后还需要使用的物体隐藏起来而不是直接Destroy掉
            - 释放AssetBundle占用的资源；AssetBundle资源包
            - 降低模型的片面数，降低模型的骨骼数量，降低贴图的大小
            - 使用光照贴图，使用多层次细节(LOD)，使用着色器(Shader)，使用预设(Prefab)
    - alpha blend 工作原理
        - 实际显示颜色 = 前景颜色*Alpha/255 + 背景颜色*(255-Alpha)/255
    - 光照计算中的diffuse的计算公式
        - 实际光照强度 I= 环境光(Iambient) + 漫反射光(Idiffuse) + 镜面高光(Ispecular)
        - 环境光：Iambient= Aintensity* Acolor;			(Aintensity环境光强度，Acolor环境光颜色)
        - 漫反射光：Idiffuse = Dintensity*Dcolor*N.L	 	(Dintensity漫反射强度，Dcolor漫反射光颜色，N法向量，L光源向量)
        - 镜面反射光：Ispecular = Sintensity*Scolor*(R.V)^n;	(Sintensity表示镜面光照强度，Scolor镜面光颜色，R为光的反射向量，V为观察者向量，n称为镜面光指数)
    - 描述MeshRender和SkinnedMeshRender的关系与不同
        - Mesh就是指模型的网格（同名组件是用于调整网格属性的）
        - MeshFilter：网格过滤器，MeshFilter决定使用哪一个Mesh。
        - MeshRender ：负责渲染 MeshFilter 指定的 Mesh，在 Transform 的位置渲染这个Mesh。
        - SkinnedMeshRenderer蒙皮网格过滤器，具有蒙皮信息（Skin数据）的 Mesh 就是SkinnedMesh。
        - 动画的网格用SkinnedMeshRenderer，静止不动的网格用MeshRender
    - MeshCollider和其他Collider的一个主要不同点
        - Meshcollider再快也是基于V3顶点，boxcollider本身是基于算法，没有面的概念
    - LOD是什么，优缺点是什么
        - LOD技术是Levels of Detail的简称，即多细节层次。LOD技术指根据物体模型的节点在显示环境中所处的位置和重要度，决定物体渲染的资源分配，降低非重要物体的面数和细节度，从而获得高效率的渲染运算。
            - 优点：可根据距离动态地选择渲染不同细节的模型;
            - 缺点：加重美工要准备不同细节的同一模型，同样的会增加游戏的容量
    - Unity AI 行为树
        - 是一棵用于控制 AI 决策行为的、包含了层级节点的树结构
**Composites（复合类）**：主要用于控制行为树的走向，也是用的最多最重要的一类，任何一个相对复杂的行为树都包含这类Task节点，但它本身不做任何具体行为，所以它们一般位于父节点或根节点。
            - Selector（选择）：相当于Or操作，下面的子Task节点只要有一个返回成功了它就返回成功，只有当所有的都返回失败了才返回失败。
            - Sequence（序列）：相当于And操作，下面的子Task节点只要有一个返回失败了它就返回失败，只有当所有的都返回成功了才返回成功。
            - Parallel Node（并发： 并发执行它的所有Child Node，指定数量的Child Node返回True或False后才决定结果。
        - **Decorators（装饰类）**：多用于对其下的子Task节点执行额外操作，例如反转结果，重复执行等。再返回给它的Parent Node
        - **Actions（行为类）**：数量最多，为具体执行行为的Task，一般位于行为树的叶子节点右侧，该类Task可能并非单帧就能完成。没必要每个Action都搞清楚，因为可以很容易的自己扩展Action。后面会具体介绍如何扩展。
        - **Conditionals（条件类）**：一般放在Action节点左侧进行约束，只有当条件满足（或不满足）时才继续往下执行，单帧内完成一次判断。更多时候配合复合节点进行打断或任务跳转，这一点后面会详细说明。

- 热更新
    - xlua 特点
        - xLua在功能、性能、易用性都有不少突破，这几方面分别最具代表性的是：
            - 可以运行时把C#实现（方法，操作符，属性，事件等等）替换成lua实现；
            - 出色的GC优化，自定义struct，枚举在Lua和C#间传递无C# gc alloc；
            - 编辑器下无需生成代码，开发更轻量；
            - 对C#的实现进行热更新。
                - 原理：需要更新的类打上[HotFix]标签后，执行XLua/Generate Code后，xLua会根据内置的模板代码生成器在XLua目录下生成一个DelegateBridge类，这个类中的__Gen_Delegate_Imp*函数会映射到xlua.hotfix中的function。在执行XLua/Hotfix inject in Editor后，xLua会使用Mono.Cecil库对当前工程下的Assembly-CSharp.dll程序集进行IL注入。IL是.NET平台上的C#、F#等高级语言编译后产生的中间代码，该中间代码IL再经.NET平台中的CLR（类似于JVM）编译成机器码让CPU执行相关指令。移动平台无法把C#代码编译成IL中间代码，热更新方案都会涉及到IL注入，Unity内置的VM才能对热更新的代码进行处理。

    - unity 热更新的底层原理？ Scripting Backend 脚本引擎后台是什么？
        参考视频讲解：https://www.bilibili.com/video/BV1Ra411c7Gz
        - 打包选项，有两种
            - Mono
                - ARMv7、x86
                - 只支持32位系统，内存最大4G, 2^32 = 4G
                - 打包后apk修改后缀为.zip，查看项目目录结构，是.dll（动态链接库,此为项目脚本文件）后缀的文件 + mono虚拟机文件(limonoXXX.so文件),.dll文件必须加载到mono虚拟机文件中执行。
            - IL2CPP
                - ARMv7、ARM64、x86
                - 支持32位、64位系统
                - 打包后无DLL文件，libil2cpp.so = libmono.so + Assembly-CSharp.dll
                - 可以显著减少构建的游戏包体大小
                - 必须提前编译
            - android 支持 Mono 和IL2CPP
            - ios 仅支持IL2CPP，此外大部分平台仅支持IL2CPP
            > ios在早期是支持Mono的Full-AOT方式，仅支持32位，但是在2016年1月平台要求所有新上架的游戏必须支持64位架构，所以必须要选IL2CPP。
        - Mono方式脚本编译流程
            - 脚本被编译成IL
                - C#code 通过Mono C# Compiler编译生成CIL(中间汇编语言，不同平台的CIL可能不一样)，在游戏运行时候，IL和项目里其他的第三方兼容的DLL一起放入Mono VM虚拟机，由虚拟机解析成机器码，并且执行。
                - 等到需要真正执行的时候，这些IL会被加载到运行时库，也就是VM中，由VM动态的编译程汇编代码（JIT）再执行
            - CLI = CIL + CLR
            ![编译流程图](/img/in-post/post-js-version/mono-complier.png "编译流程图")
                - 编译：通过C#编译器，运行前把C#编译成CIL（实现平台无关汇编）
                - 运行：通过CLR，在运行时把CIL转换成各平台的原生码
                >  CLI: Common Language Infrastructure 公共语言基础结构 | CIL: Common Intermediate Language 公共中间语言 | CLR: Common Language Runtime
            - CRL 通用语言平台，是微软的.Net虚拟机
                - 抽象了平台相关部分，因为windows、linux、android等操作系统的以下行为是不一样的（如进程线程管理、内存分配、垃圾回收、文件管理等），并在运行时调用平台相关的实现。
            - Mono
                - 一个基于CLR的开源项目，运行引擎和用户的托管代码运行在每一个目标平台上
                - 微软的传统虚拟机叫做.NET平台虚拟机，本身是不支持跨平台的，经过mono的移植，才可以支持跨平台。unity也是利用mono这个开源项目实现跨平台
            - Mono虚拟机如何运行CIL？
                - JIT（Just In Time）模式。在编译的时候，把C#编译成CIL，在运行时，逐条读入，逐条解析成原生码交给CPU再执行
                - AOT（Ahead Of Time）模式。在编译程CIL之后，会把CIL再处理一边，编译成原生码，在运行的时候交给CPU直接执行，Mono下的AOT只会处理部分的CIL，还有一部分CIL采用JIT的模式
                - Full AOT。在编程CIL之后，把所有的CIL编译成原生码，在运行时的时候直接执行
                    - 不允许运行时动态加载代码了，也就是说**不支持热更**，如ios只支持Full AOT,andorid支持三种。
                    - 安全性比较好
        - IL2CPP方式脚本编译流程
            ![IL2CPP编译流程图](/img/in-post/post-js-version/il2cpp-complier.png "IL2CPP编译流程图")
            - C#code 通过Mono C# Compiler编译生成CIL，通过IL2CPP将CIL重新编程C++代码，然后再由各个平台的C++编译器（例:x86：vc++,linux、android:gcc）直接编译程能执行的原生汇编代码,然后通过IL2CPP VM虚拟机生成机器码
            - 仅支持AOT方式
        - 理想的热更流程
            - 热更的功能写在一个DLL中
            - 游戏启动时用新的同名DLL覆盖旧的
            - Assembly.Load动态加载该DLL
            - 反射创建热更DLL中的类的实例或静态方法
            - 这么简单？理论上android支持jit，所以是可以的。但是ios不支持，因为ios禁止为动态分配内存赋予执行权限
        ```C++
        void* create_space(size_t size) {
            void* ptr = mmap(0, size, PROT_READ | PROT_WRITE | PROT_EXEC，
                    MAP_PRIVATE | MAP_ANON, -1, 0);
            return ptr;
        }
        // 本段C++代码相当于创建一块内存，并未内存赋予权限，在windows、android上是正常的。
        //在ios平台上会报错，ios禁止为动态创建的内存赋予执行权限，PROT_EXEC是禁止的。
        ```
        - 所以只能采用静态编译
            - Mono的Full-AOT
            - IL2CPP
            - 但也不能完全避免问题。在IOS平台上运行的程序,如果在运行的时候才知道泛型的实际类型，用上述2种编译会直接跳过这段代码的编译，编译器会认为说我既然是静态编译的，就不能执行在程序运行中动态指令的代码，会导致报错，如下：

            ![ios代码](/img/in-post/post-js-version/complier-ios.png "ios代码")
            - 怎么解决？
                - 比较不好的解决方法。强制AOT生成具象类型代码，这样就丧失的泛型的灵活性。如：OnMessage(AnyEnum.Zero);需要思考有没有更好的办法？思考kow项目中tolua 是怎么解决的
        - 解决方案
            - 所以要嵌入脚本语言
                - lua
                    - ToLua /XLua，ios和android都是用lua脚本热更，基于lua虚拟机
                - C#
                    - ILRuntime,未来更有前景，需要了解一下，毕竟unity官方支持。。
                        - ios用c#脚本热更（运行效率跟lua差不多），android直接用C#反射热更
            - LUA/ILRuntime热更方案都会把脚本加载到内存并执行，那么这两种方式就能正常执行动态加载的脚本呢？
                - 拿lua来举例，脚本语言工作原理：每次启动游戏的时候首先从服务器检测脚本更新，如果有更新就下载到客户端，客户端启动后，脚本会加载到内存中运行，由lua虚拟机负责解释执行脚本
                - lua热更比C#热更缺点：
                    - 学习成本提高
                    - 招聘成本提高
                    - 引擎层到脚本层的转换会降低程序执行效率。增加lua虚拟机来执行lua脚本，增加了一层unity的C#到lua脚本的开销。
        - 小结与思考
            - unity的脚本后台有哪几种
            - 每种脚本后台分别支持哪几种编译方式
            - 安卓/苹果分别可以选择哪几种编译方式
            - C#脚本对反射的使用有限制，那么什么样反射方法可以使用呢？ 反射又是啥？
            - .net项目和netcore项目之前的区别
            - 热更新的底层原理
            - 热更新GC问题
            - 热更新的lua代码的对象绑定问题
        - 进一步学习内容
            - 资源热更新框架
                - 如何打包资源
                - 如何上传资源
                - 如何进行版本比对
                - 如何环节资源更新服务器的压力
            - 脚本热更新框架
            - lua脚本语言的学习？lua面向对象
            - ToLua/ILRuntime热更新方案及其背后各项技术的原理
                - 如何实现绑定
                - 如何实现反射
                - 如何实现重定向
    - 还能想到什么更好用的热更方式
        - 二进制差量热更新
- lua
    - c#和lua的互相调用
    - lua和unity的GC
        - 死锁问题，lua的引用和unity 的引用互相等待对方释放，可能造成内存溢出
    - lua协程
    - 元表、元方法
    - 如何实现面向对象
        - metatable,在一个table中，如果索引一个元素(元素或方法)未能找到，解释器会去该table下的metatable中的__index元素中去寻找
        - 云风, 定义了一个函数 class(classname, super) ,用这个函数，我们就可以方便的在lua 中定义类
        - class内部实现了构造函数ctor和new方法,new方法为创建对象时候创建实例并自动调用ctor方法
    - lua代码的性能瓶颈定位与优化
        - CPU
            - CPU 代码分支预测器
                - 排序后的数组对比乱序的数组遍历速度快很多,因为cpu执行大量if,switch判断的时候会预测一个大概的分支,排序后的数组缓存命中率比较高
            - 找到瓶颈函数，一旦找到瓶颈函数，接下去的优化过程无非就是优化方案，无非就是修改实现，或者通过策略减少瓶颈函数的调用。
            - 思考？通过什么手段快速找到瓶颈函数
        - 内存
            - 总内存,lua本身有函数可以直接查询当前的总内存占用。监控总内存主要是为检查内存泄漏。内存泄露一般出现在与另外一个语言交互过程导致的。操作过程：查看总内存曲线，luagc能把总内存降低在一个正常的水平说明没问题。至于内存占用多少，具体看游戏项目类型了。十几M到一百多M都有~
            > collectgarbage("count"): 以 K 字节数为单位返回 Lua 使用的总内存数。 这个值有小数部分，所以只需要乘上 1024 就能得到 Lua 使用的准确字节数（除非溢出）
            - 临时分配->Lua GC
                - lua中做大量临时分配容易造成lua频繁GC，虽然lua在5.3之后是分布执行GC。也就是说触发Lua GC，lua不会在一帧内强制把所有的垃圾回收都执行一遍，而是在持续一段时间内，每帧去做一定的GC工作，相对来说比较不会造成明显的卡顿，但是会造成CPU上的一些耗时。
                - 如何减少临时分配
                    - 尽可能复用一些table。
                    - 思考还有什么。。
        - 工具：
            - https://www.uwa4d.com/#download UWAGOT
            - https://github.com/leinlin/Miku-LuaProfiler lua profiler

- 图形学
    - 叉乘和点乘的意义
        - 叉乘
            - 几何意义：得到一个与这两个向量都垂直的向量，这个向量的模是以两个向量为边的平行四边形的面积
            - 在同一平面内， 结果 > 0 表示 B在A的逆时针方向， 结果 <0 表示B在A的顺式针方向， 结果 = 0表示B与A同向
            - 应用：计算两个向量方向的
        - 点乘
            - 几何意义：可以用来表征或计算两个向量之间的夹角，以及在b向量在a向量方向上的投影
            - 两个向量的点乘所得到的是两个向量的余弦值，也就是-1 到1之间，0表示垂直，-1表示相反，1表示相同方向。
            - 应用：计算两个向量方向的夹角
    - 四元数
    - 渲染流程讲一下
    - unity shader
        - 什么是Shader？
            - Shader就是着色器,就是专门用来渲染图形的一种技术，通过shader，我们可以自定义显卡渲染画面的算法，使画面达到我们想要的效果。
        - Shader分为两类
            - 顶点Shader(Vertex Shader): 3D图形都是由一个个三角面片组成的，顶点Shader就是计算每个三角面片上的顶点，并为最终像素渲染做准备;
            - 像素Shader(Fragment Shader):以像素为单位，计算光照、颜色的一系列算法;
        - Unity Shader
            - Shader编程语言有GLSL、HLSL、Cg等；Unity Shader是Unity自身封装后的一种便于书写的Shader，又称为ShaderLab；主要写法Surface Shaders 表面着色器，Vertex/Fragment Shaders 顶点/片断着色器。
        - Shader与材质的关系
            - 一个Shader可以与无数个材质关联。一个材质同一时刻只能关联于一个Shader。
            - 材质可以赋与模型，但是Shader不行。
            - 材质就像是Shader的实例，每个材质都可以参数不一样呈现不同的效果，但是当Shader改变时，关联它的所有材质都会相应的改变。
        - Shaders的结构

            ```
            Shader "name" { //Shader名称路径；
            [Properties] {}	  //材质球面板中显示的贴图和一些参数什么的都是在此Properties中进行定义设置的；
            SubShaders  //shader的主体，Pass的意思就是渲染一次模型，由CGPROGRAM开始，由ENDCG结束；
            {
            Pass { 
            CGPROGRAM 
            #pragma vertex vert 
            #pragma fragment frag 
            #pragma surface surf Standard fullforwardshadows
            fixed4 _Color; 
            float4 vert ( float4 vertex : POSITION ) : SV_POSITION	 //顶点
            { 
                return UnityObjectToClipPos(vertex); 
            } 
                fixed4 frag () : SV_Target 		//片段
            { 
                return _Color;
            } 
            void surf (Input IN, inout SurfaceOutputStandard o) //表面着色器
            {
            }
            ENDCG
            }
            }
            [FallBack] 	  //备胎shader的路径，遇到不支持的时候来处理的；
            [CustomEditor]  //自由定义材质面板的显示结果，它可以改写Properties中定义的显示方式；
            ```


    - 什么是渲染管道
        - 渲染管线也称为渲染流水线，是我们准备一些数据，让GPU对这些数据做一些处理，最后得出一张二维图像，渲染流程主要分为几个大的阶段：
            - 数据准备阶段：根据用户提供的顶点及索引信息，构建多边形，数据包括顶点数据（位置，法线，颜色，纹理坐标）和常量（世界矩阵，观察矩阵，投影矩阵，纹理因子等）;
            - 顶点处理阶段：是通过一系列坐标系的变换，让各个顶点通过一定的规律在摄像机前位移，最终在屏幕上对应这些顶点的过程;
            - 光栅操作阶段：合并阶段。它的主要功能是将面转换成一帧中的像素集合;
            - 像素着色阶段：将像素区域着色，然后赋予贴图;
    - 前向渲染和延迟渲染的区别
        - 前向渲染和延迟渲染是两种光照渲染模式。
            - 前向渲染：先渲染一遍物体，把法线和高光存在ARGB32的渲染纹理中（法线用rgb通道，高光用a通道），存在了z buffer里；然后通过深度信息，法线和高光信息计算光照（屏幕空间），光照信息缓存在Render Texture中；最后混合。如果是逐像素的，复杂度：片段的个数*光照的个数。
            - 延迟渲染：先不进行光照运算，对每个像素生成一组数据(G-buffer)，包括位置，法线，高光等，然后用这些数据将每个光源以2D后处理的方式施加在最后图像上（屏幕空间）。复杂度：屏幕的分辨率*光源个数。
    - OpenGL中要用到哪几种Buffer？
        - 帧缓冲(Frame Buffer)：用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲，这些缓冲结合起来叫做帧缓冲(Framebuffer)，它被储存在内存；
        - 模板缓冲(Stencil Buffer)：与深度缓冲大小相同,通过设置模版缓冲每个像素的值,我们可以指定在渲染的时候只渲染某些像素,从而可以达到一些特殊的效果；
        - 顶点缓冲(Vertice Buffer)：直接将顶点数据存储在gpu的一段缓冲区，不需要从cpu拷贝到gpu。提高了程序的运行效率；
        - 深度缓冲(Depth Buffer) ：与帧缓冲区对应,用于记录上面每个像素的深度值,通过深度缓冲区,我们可以进行深度测试,从而确定像素的遮挡关系,保证渲染正确；
        - 渲染缓冲(render Buffer)：可用于分配和存储颜色，深度或模板值，并可用作帧缓冲区对象中的颜色，深度或模板附件；



- 其它
    - 鸿蒙与安卓的对比
        - 系统定位
            - 安卓系统面向的是手机端
            - 鸿蒙系统面向的是这些年比较的新的概念物联网，致力于利用其5G世界领先的技术,优先布局一个超级终端，万物互联的生态
        - 内核对比
            - 安卓系统基于linux的宏内核设计 ，宏内核包含了操作系统绝大多数的功能和模块，而且这些功能和模块都具有最高的权限，只要一个模块出错，整个系统就会崩溃，这也是安卓系统容易崩溃的原因。系统开发难度低。
            - 基于微内核设计，微内核仅包括了操作系统必要的功能模块（任务管理、内存分配等）处在核心地位具有最高权限，其他模块不具有最高权限，也就是说其他模块出现问题，对于整个系统的运行是没有阻碍的。微内核稳定性很高
        - 运行速度
            - 安卓系统基于Java语言编码，Java语言有个很大的缺点是其不能直接与底层操作系统通信，需要通过虚拟机充当中间转换的角色.虽然Java语言由于虚拟机的优化，编译器的优化，热点代码等技术使得其越来越快，但是无法直接与操作系统互相通信一直影响着其性能的突破
            - 鸿蒙的开发也可以采用Java语言.但是华为针对安卓或者说Java语言的这种特性，研发了方舟编译器，通过方舟编译器编译的软件可以直接与底层操作系统通信，方舟编译器在这一层面做到了取代虚拟机
                - 它不采用现有编译器边解释边执行的模式，而是将这种动态编译改为静态编译，可以做到全程执行机器码，进而高效运行程序，大大缩短程序响应时间
                - 推断应该是在打包的时候，通过方舟编译器转换为操作系统能够读懂的机器语言，这样就可以跳过虚拟机解释这一步骤，当然这是肯定对机器的内存要求比较高，应该也存在启动后无法继续优化等问题

- 数据库
    - sql
        - 事务
            - 如何执行? commit rollback
            - ACID：
                - 原子性(数据修改要么全执行,要么全不执行)
                - 一致性(事务执行前后数据库数据保持一致性,避免脏读)
                - 隔离性(多个事务并发执行,互相隔离,执行事务T1,才能执行事务T2),有四种隔离级别
                    - 读取未提交：读取不加锁
                    - 读取已提交：读取加共享锁，语句完成后释放
                    - 可重复读：读取加共享锁，事务提交后释放
                    - 可串行化：所有事务依次执行
                    - MVCC：写操作更新最新版本快照，读操作读旧版本快照
                    - Next-Key Locks：锁定一个记录上的索引和索引间隙
                - 持久性
                    - 事务完成后修改是永久性的,半途中出现故障由数据库备份和恢复来保证.
                        - 数据备份种类
                            - 完全备份
                            - 差异备份
                            - 事务日志备份
                            - 增量备份
                        - 数据库日志满了(log file),出现什么,只能执行查询操作,因为任何写操作都要记录日志
        - 并发一致性问题：丢失修改，读脏数据，不可重复读，幻读
        - 锁：
            - 粒度：行锁，表锁
            - 类型：互斥锁(用于数据修改操作)，共享锁(读锁)
            - 实现：乐观锁，悲观锁
        - 范式
            - 1NF：属性不可分(属性不能由多个值或重复的属性),如职工(职工号,姓名,电话)
            - 2NF：非主属性完全依赖于键码,如 学生表(学号,课程号,分数)和课程表(课程号,学分)
            - 3NF：非主属性不传递依赖于键码
            - BCNF：对于函数依赖X->Y，X必须包含码
        - 索引
            - waht? 按照某个关键字段的值,升序或降序排序创建的对象,借助索引,再执行查询的时候不需要扫描整个表可以快速找到数据
            - 哈希：查询快，不支持范围查询
            - 数组：查询快，插入慢
            - B+树：查询快，插入快
        - 存储引擎
            - innodb：聚集索引，行锁，高并发
            - myisam：非聚集索引，表锁
        - MySQL优化：
            - 设计：存储引擎、范式与逆范式、字段类型
            - 功能：索引、缓存、分区分表
            - 架构：主从复制、读写分离、负载均衡
    - nosql

- 海量数据处理问题
    - 基本方法
        - Hash法
            - 作用: **无序**.主要用来**快速存取,统计数据,大量数据分类**
            - **固定大小**的数组,表长应该为**质数**
                - 哈希表的长度使用质数，可以降低发生冲突的概率，使哈希后的数据更加均匀，如果使用合数，可能会导致很多数据集中分布到一个点上，造成冲突；
            - 构建方法有很多,常见三个如下
                - 直接寻址法, h(key) = key 或h(key) = a*key+b,a,b均为整型常数
                    - 不会产生冲突,但是效率比较低,不会实现地址编码的偏移
                - 取模法
                    - hash(key) = Key Mod p, p 为哈希表的长度
                - 除留余数法 Hash(key) = key % p
            - 解决冲突
                - 开放地址法
                    - H(key)有值了,则继续查看地址为H(key) + d的存储地址是否有值,反复知道找到空闲存储地址.增量d可以有多种取法:如d = 1,2,3,4...
                - 链地址法
                    - 链表.该方法适用于冲突比较严重的情况
                - 再散列法
                    - 当发生冲突的时候,使用第二,第三个哈希函数计算地址,直到无冲突.缺点:计算时间增加
                - 建立一个公共溢出区
                    - hash函数的值域[0,m-1], 基本表为[0,m-1],overTable[0, ...,v]
        - Bit-map法
            - 使用位数组来表示某些元素是否存在,适用于海量数据的快速查找 判重 删除
            - 实现
                - 首先扫描一遍数组找出最大的元素max
                - 创建一个长度为max+1的新数组
                - 扫描原数组,没遇到一个元素就在新数组下标为元素值的位上置1
        - Bloom fitter法 布隆过滤器
            - https://www.bilibili.com/video/BV1zK4y1h7pA
            - 本质是一个**二进制的数组**
            - 主要作用:判断一个数据是否在数组里
                - 为什么设计布隆过滤器.场景: 查找一个嫌疑人的名字是否在名单上
                    - 将集合所有元素存储,每当遇到一个新元素直接与集合中元素进行比较即可,在海量数据情况下,**存储效率低**
            - 特色:牺牲正确率,来换取空间效率与时间效率的提高
                - 判断元素是否属于集合,两种结果:1. 不属于这个集合(必然正确) 2.属于这个集合(可能错误)
            - 过程
                - 插入过程
                    - 多个哈希函数返回多个位数组上的第K位,将这些值设置为1
                - 查询过程
                    - 通过多个哈希函数返回多个维数组上的第K位,如果有的位不为1,代表不存在,如果都为1,可能存在(为什么说可能?)
                    > 不同元素可能存在象统的哈希值,所以会存在:**不存在集合中却返回存在**的误判
                - 删除操作
                    - 很难操作,位设为0.如果2个元素位一样,删除一个,另一个也删除了
            - 优点 
                - 二进制数组组成的数据,空间很小,保密性好(因为是二进制)
                - 查询和插如速度很快(时间复杂度O(K),K代表哈希函数的个数)
            - 缺点
                - 不支持删除操作
                - 误判(不存在集合中却返回存在),不可避免
            - 如何减少误判的概率?或者 为什么需要多个哈希函数
                - 一般调用库里面的布隆过滤器,有一个传参数fpp(误判率,默认0.01),越小计算时间越长,误判率越低
                - 误判率底层原理
                    - 误判率越小,所需要的哈希函数越多,所占用的空间越大
                    > 假如只有一个哈希函数,不同数据得到相同的哈希值相同的概率就越大,二进制数据空间也比较小
            - 应用:布隆过滤器可以解决缓存穿透
                > 缓存穿透:前端查询一个数据,但是redis没有这个数据,直接从数据库查询,海量查询,数据库压力大
                - 缓存穿透,有大量的请求数据在缓存中没有而且数据库也没有,全部打在了数据库上.
                - 布隆过滤器的二进制数据是全局的,若数据库中存在数据,那么布隆过滤器就会在该数据请求过后标记数据的存在. 从而避免其他大量数据库不存在的数据请求
        - 数据库优化法
        - 倒排索引法
            - 应用:搜索引擎最常用的存储方法
            - 正向索引和倒排索引的区别
                - 正向:文档指向了它包含的单词列表,根据玩当找关键词
                - 反向:单词指向包含它的文档,根据关键词找文档
                - 倒排对比正向优点:
                    - 节省空间
                    - 处理复杂的多关键词查询,可以直接在倒排表中完成查询的并,交等运算
            - 过程
                - 文章录入的时候,对文章分词形成分词索引,网站搜索关键词时候根据关键词在分词索引数组中查找并返回文章内容及相关关键词位置信息
        - 外排序法
            - 使用场景,待排序的对象数目特别多,在内存中不能一次处理.需把数据以文件形式存放于外存,排序时再把他们分批调入内存排序.
            - 一般采用**归并排序**实现外排序
            - 缺点
                - 消耗大量IO,效率低
        - Trie树(字典树或前缀树)

            ![Trie树](/img/in-post/post-js-version/trie_1.png)

            - 结构
                - root根节点, root = Trie(),空节点
                - 孩子节点, HashMap<'字符', Trie()>
                - 结束词标记flag
            - 应用
                - 被搜索引擎系统用于**文本词频统计**,适用于数据大,重复多.
                - 根据保存的字典,预测用户输入内容
                - 断词和拼写查错
            - 优点:最大限度减少无谓的字符串比较
            - 缺点如果系统中有大量字符串且基本没有公共前缀,则trie树就很消耗内存
            - leetcode
                - 208 实现tried(insert, search, startWith)
                - 720 词典中最长的单词
                - 692 前K个高频单词
        - 堆(二叉堆)
            - 概念:https://www.jianshu.com/p/579b7c5148fd
            ![Trie树](/img/in-post/post-js-version/heap_1.png)

            - 特征
                - 除了最底层,二叉树是完全充满的,且最底层节点从左到右依次填充
            - 最大堆
                - 堆的根节点值最大
                - 根节点的两个子树也是大顶堆
            - 应用:海量数据求前N大或前N小的问题,N一般比较小
                - 求前n小,最大堆
                - 求前n大,最小堆
                - 求海量数据中前n大/小的值中位数: 双堆
        - 双层桶法?有点没看懂
            - 应用场景:寻找第K大的数,寻找中位数,寻找不重复或重复的数字等
            - 桶排序
        - MapReduce法
    - 有10个500M的日志文件,文件内容按照时间戳排序,在内存只有1G的情况下如何合并成一个文件,并且仍然有序
        - https://www.bilibili.com/video/BV1JN411Z7k4
        - 多路归并排序(最小堆)
        - 利用I/O流思路,创建10个IO流,分别取10个中最小的时间戳写入新文件
- 加密问题
    - 游戏防作弊
        - 怎么做？
            - 用配置文件限定防作弊数值范围
                - 如果解包更改配置文件，有办法能够防止吗？
                    - 配置文件用ab加密
                        - ab如何加密的呢？加密解密，LoadFromMemory会造成什么问题？大批量造成内存过大？如何解决内存过大 （这个方案带来的次生风险更大）
                    - 还有什么方法？
                        - Anti-Cheat Toolkit https://www.bilibili.com/video/av668088669/

- 逻辑
    - 判断一个数是不是2的整数次幂

        ```csharp
        public static bool isPowerOf2(int num) {
            return (num & num - 1) == 0;
        }
        ```
